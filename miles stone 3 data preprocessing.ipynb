{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c4ad6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 import the lib\n",
    "import pandas as pd #For data related tasks\n",
    "import matplotlib.pyplot as plt #for data visualization \n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d840a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a873f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c44a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Close</th>\n",
       "      <th>Total Trade Quantity</th>\n",
       "      <th>Turnover (Lacs)</th>\n",
       "      <th>stock_price_change_in _percentage</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/10/2018</td>\n",
       "      <td>208.00</td>\n",
       "      <td>222.25</td>\n",
       "      <td>206.85</td>\n",
       "      <td>216.00</td>\n",
       "      <td>215.15</td>\n",
       "      <td>4642146.0</td>\n",
       "      <td>10062.83</td>\n",
       "      <td>3.4375</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/10/2018</td>\n",
       "      <td>217.00</td>\n",
       "      <td>218.60</td>\n",
       "      <td>205.90</td>\n",
       "      <td>210.25</td>\n",
       "      <td>209.20</td>\n",
       "      <td>3519515.0</td>\n",
       "      <td>7407.06</td>\n",
       "      <td>-3.594470046</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/10/2018</td>\n",
       "      <td>223.50</td>\n",
       "      <td>227.80</td>\n",
       "      <td>216.15</td>\n",
       "      <td>217.25</td>\n",
       "      <td>218.20</td>\n",
       "      <td>1728786.0</td>\n",
       "      <td>3815.79</td>\n",
       "      <td>-2.371364653</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/10/2018</td>\n",
       "      <td>230.00</td>\n",
       "      <td>237.50</td>\n",
       "      <td>225.75</td>\n",
       "      <td>226.45</td>\n",
       "      <td>227.60</td>\n",
       "      <td>1708590.0</td>\n",
       "      <td>3960.27</td>\n",
       "      <td>-1.043478261</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/10/2018</td>\n",
       "      <td>234.55</td>\n",
       "      <td>234.60</td>\n",
       "      <td>221.05</td>\n",
       "      <td>230.30</td>\n",
       "      <td>230.90</td>\n",
       "      <td>1534749.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.556171392</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open    High     Low    Last   Close  Total Trade Quantity  \\\n",
       "0  08/10/2018  208.00  222.25  206.85  216.00  215.15             4642146.0   \n",
       "1  05/10/2018  217.00  218.60  205.90  210.25  209.20             3519515.0   \n",
       "2  04/10/2018  223.50  227.80  216.15  217.25  218.20             1728786.0   \n",
       "3  03/10/2018  230.00  237.50  225.75  226.45  227.60             1708590.0   \n",
       "4  01/10/2018  234.55  234.60  221.05  230.30  230.90             1534749.0   \n",
       "\n",
       "   Turnover (Lacs) stock_price_change_in _percentage     trend  \n",
       "0         10062.83                            3.4375  positive  \n",
       "1          7407.06                      -3.594470046  negative  \n",
       "2          3815.79                      -2.371364653  negative  \n",
       "3          3960.27                      -1.043478261  negative  \n",
       "4              NaN                      -1.556171392  negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Load the dataset----Read the dataset\n",
    "data=pd.read_csv(\"NSE-Tata-Global-Beverages-Limited (1).csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e66a19ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1235 entries, 0 to 1234\n",
      "Data columns (total 10 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Date                               1235 non-null   object \n",
      " 1   Open                               1223 non-null   float64\n",
      " 2   High                               1230 non-null   float64\n",
      " 3   Low                                1234 non-null   float64\n",
      " 4   Last                               1232 non-null   float64\n",
      " 5   Close                              1234 non-null   float64\n",
      " 6   Total Trade Quantity               1233 non-null   float64\n",
      " 7   Turnover (Lacs)                    1232 non-null   float64\n",
      " 8   stock_price_change_in _percentage  1235 non-null   object \n",
      " 9   trend                              1235 non-null   object \n",
      "dtypes: float64(7), object(3)\n",
      "memory usage: 96.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8900ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Close</th>\n",
       "      <th>Total Trade Quantity</th>\n",
       "      <th>Turnover (Lacs)</th>\n",
       "      <th>stock_price_change_in _percentage</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/10/2018</td>\n",
       "      <td>208.00</td>\n",
       "      <td>222.25</td>\n",
       "      <td>206.85</td>\n",
       "      <td>216.00</td>\n",
       "      <td>215.15</td>\n",
       "      <td>4642146.0</td>\n",
       "      <td>10062.83</td>\n",
       "      <td>3.4375</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/10/2018</td>\n",
       "      <td>217.00</td>\n",
       "      <td>218.60</td>\n",
       "      <td>205.90</td>\n",
       "      <td>210.25</td>\n",
       "      <td>209.20</td>\n",
       "      <td>3519515.0</td>\n",
       "      <td>7407.06</td>\n",
       "      <td>-3.594470046</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/10/2018</td>\n",
       "      <td>223.50</td>\n",
       "      <td>227.80</td>\n",
       "      <td>216.15</td>\n",
       "      <td>217.25</td>\n",
       "      <td>218.20</td>\n",
       "      <td>1728786.0</td>\n",
       "      <td>3815.79</td>\n",
       "      <td>-2.371364653</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/10/2018</td>\n",
       "      <td>230.00</td>\n",
       "      <td>237.50</td>\n",
       "      <td>225.75</td>\n",
       "      <td>226.45</td>\n",
       "      <td>227.60</td>\n",
       "      <td>1708590.0</td>\n",
       "      <td>3960.27</td>\n",
       "      <td>-1.043478261</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/10/2018</td>\n",
       "      <td>234.55</td>\n",
       "      <td>234.60</td>\n",
       "      <td>221.05</td>\n",
       "      <td>230.30</td>\n",
       "      <td>230.90</td>\n",
       "      <td>1534749.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.556171392</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>14/10/2013</td>\n",
       "      <td>160.85</td>\n",
       "      <td>161.45</td>\n",
       "      <td>157.70</td>\n",
       "      <td>159.30</td>\n",
       "      <td>159.45</td>\n",
       "      <td>1281419.0</td>\n",
       "      <td>2039.09</td>\n",
       "      <td>-0.870376127</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>11/10/2013</td>\n",
       "      <td>161.15</td>\n",
       "      <td>163.45</td>\n",
       "      <td>159.00</td>\n",
       "      <td>159.80</td>\n",
       "      <td>160.05</td>\n",
       "      <td>1880046.0</td>\n",
       "      <td>3030.76</td>\n",
       "      <td>-0.682593857</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>10/10/2013</td>\n",
       "      <td>156.00</td>\n",
       "      <td>160.80</td>\n",
       "      <td>155.85</td>\n",
       "      <td>160.30</td>\n",
       "      <td>160.15</td>\n",
       "      <td>3124853.0</td>\n",
       "      <td>4978.80</td>\n",
       "      <td>2.66025641</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>09/10/2013</td>\n",
       "      <td>155.70</td>\n",
       "      <td>158.20</td>\n",
       "      <td>154.15</td>\n",
       "      <td>155.30</td>\n",
       "      <td>155.55</td>\n",
       "      <td>2049580.0</td>\n",
       "      <td>3204.49</td>\n",
       "      <td>-0.096339114</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>08/10/2013</td>\n",
       "      <td>157.00</td>\n",
       "      <td>157.80</td>\n",
       "      <td>155.20</td>\n",
       "      <td>155.80</td>\n",
       "      <td>155.80</td>\n",
       "      <td>1720413.0</td>\n",
       "      <td>2688.94</td>\n",
       "      <td>-0.76433121</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1235 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date    Open    High     Low    Last   Close  \\\n",
       "0     08/10/2018  208.00  222.25  206.85  216.00  215.15   \n",
       "1     05/10/2018  217.00  218.60  205.90  210.25  209.20   \n",
       "2     04/10/2018  223.50  227.80  216.15  217.25  218.20   \n",
       "3     03/10/2018  230.00  237.50  225.75  226.45  227.60   \n",
       "4     01/10/2018  234.55  234.60  221.05  230.30  230.90   \n",
       "...          ...     ...     ...     ...     ...     ...   \n",
       "1230  14/10/2013  160.85  161.45  157.70  159.30  159.45   \n",
       "1231  11/10/2013  161.15  163.45  159.00  159.80  160.05   \n",
       "1232  10/10/2013  156.00  160.80  155.85  160.30  160.15   \n",
       "1233  09/10/2013  155.70  158.20  154.15  155.30  155.55   \n",
       "1234  08/10/2013  157.00  157.80  155.20  155.80  155.80   \n",
       "\n",
       "      Total Trade Quantity  Turnover (Lacs) stock_price_change_in _percentage  \\\n",
       "0                4642146.0         10062.83                            3.4375   \n",
       "1                3519515.0          7407.06                      -3.594470046   \n",
       "2                1728786.0          3815.79                      -2.371364653   \n",
       "3                1708590.0          3960.27                      -1.043478261   \n",
       "4                1534749.0              NaN                      -1.556171392   \n",
       "...                    ...              ...                               ...   \n",
       "1230             1281419.0          2039.09                      -0.870376127   \n",
       "1231             1880046.0          3030.76                      -0.682593857   \n",
       "1232             3124853.0          4978.80                        2.66025641   \n",
       "1233             2049580.0          3204.49                      -0.096339114   \n",
       "1234             1720413.0          2688.94                       -0.76433121   \n",
       "\n",
       "         trend  \n",
       "0     positive  \n",
       "1     negative  \n",
       "2     negative  \n",
       "3     negative  \n",
       "4     negative  \n",
       "...        ...  \n",
       "1230  negative  \n",
       "1231  negative  \n",
       "1232  positive  \n",
       "1233  negative  \n",
       "1234  negative  \n",
       "\n",
       "[1235 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7edbb35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d116f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1235, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ac93a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1296 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now see some correalations between data\n",
    "import seaborn as sns\n",
    "plt.figure(1 , figsize = (18 , 18))\n",
    "cor = sns.heatmap(data.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0fcb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26edcc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f89edc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cd0103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652b960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7f791f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename( columns={'Turnover (Lacs)':'Turnover'} ,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a5e599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Last</th>\n",
       "      <th>Close</th>\n",
       "      <th>Total Trade Quantity</th>\n",
       "      <th>Turnover</th>\n",
       "      <th>stock_price_change_in _percentage</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/10/2018</td>\n",
       "      <td>208.00</td>\n",
       "      <td>222.25</td>\n",
       "      <td>206.85</td>\n",
       "      <td>216.00</td>\n",
       "      <td>215.15</td>\n",
       "      <td>4642146.0</td>\n",
       "      <td>10062.83</td>\n",
       "      <td>3.4375</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/10/2018</td>\n",
       "      <td>217.00</td>\n",
       "      <td>218.60</td>\n",
       "      <td>205.90</td>\n",
       "      <td>210.25</td>\n",
       "      <td>209.20</td>\n",
       "      <td>3519515.0</td>\n",
       "      <td>7407.06</td>\n",
       "      <td>-3.594470046</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/10/2018</td>\n",
       "      <td>223.50</td>\n",
       "      <td>227.80</td>\n",
       "      <td>216.15</td>\n",
       "      <td>217.25</td>\n",
       "      <td>218.20</td>\n",
       "      <td>1728786.0</td>\n",
       "      <td>3815.79</td>\n",
       "      <td>-2.371364653</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03/10/2018</td>\n",
       "      <td>230.00</td>\n",
       "      <td>237.50</td>\n",
       "      <td>225.75</td>\n",
       "      <td>226.45</td>\n",
       "      <td>227.60</td>\n",
       "      <td>1708590.0</td>\n",
       "      <td>3960.27</td>\n",
       "      <td>-1.043478261</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/10/2018</td>\n",
       "      <td>234.55</td>\n",
       "      <td>234.60</td>\n",
       "      <td>221.05</td>\n",
       "      <td>230.30</td>\n",
       "      <td>230.90</td>\n",
       "      <td>1534749.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.556171392</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open    High     Low    Last   Close  Total Trade Quantity  \\\n",
       "0  08/10/2018  208.00  222.25  206.85  216.00  215.15             4642146.0   \n",
       "1  05/10/2018  217.00  218.60  205.90  210.25  209.20             3519515.0   \n",
       "2  04/10/2018  223.50  227.80  216.15  217.25  218.20             1728786.0   \n",
       "3  03/10/2018  230.00  237.50  225.75  226.45  227.60             1708590.0   \n",
       "4  01/10/2018  234.55  234.60  221.05  230.30  230.90             1534749.0   \n",
       "\n",
       "   Turnover stock_price_change_in _percentage     trend  \n",
       "0  10062.83                            3.4375  positive  \n",
       "1   7407.06                      -3.594470046  negative  \n",
       "2   3815.79                      -2.371364653  negative  \n",
       "3   3960.27                      -1.043478261  negative  \n",
       "4       NaN                      -1.556171392  negative  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "756b87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna()---handle the missing values (option-1)\n",
    "mean_Close=data['Close'].mean()\n",
    "data['Close'].fillna(mean_Close, inplace=True)\n",
    "mean_Close=data['Close'].mean()\n",
    "data['Close'].fillna(mean_Close, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51739d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_Open=data['Open'].mean()\n",
    "data['Open'].fillna(mean_Open, inplace=True)\n",
    "mean_Open=data['Open'].mean()\n",
    "data['Open'].fillna(mean_Open, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47b2d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date                                  0\n",
    "# # Open                                 12\n",
    "# High                                  5\n",
    "## Low                                   1\n",
    "# Last                                  3\n",
    "# #Close                                 1\n",
    "# Total Trade Quantity                  2\n",
    "# Turnover (Lacs)                       3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03f184cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_High=data['High'].mean()\n",
    "data['High'].fillna(mean_High, inplace=True)\n",
    "mean_High=data['High'].mean()\n",
    "data['High'].fillna(mean_High, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "974187b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_Low=data['Low'].mean()\n",
    "data['Low'].fillna(mean_High, inplace=True)\n",
    "mean_High=data['High'].mean()\n",
    "data['High'].fillna(mean_High, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1bbdb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_Total_Trade_Quantity=data['Total Trade Quantity'].mean()\n",
    "data['Total Trade Quantity'].fillna(mean_Total_Trade_Quantity, inplace=True)\n",
    "mean_Total_Trade_Quantity=data['Total Trade Quantity'].mean()\n",
    "data['Total Trade Quantity'].fillna(mean_Total_Trade_Quantity, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7e8e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_Turnover=data['Turnover'].mean()\n",
    "data['Turnover'].fillna(mean_Turnover,inplace=True)\n",
    "mean_Turnover=data['Turnover'].mean()\n",
    "data['Turnover'].fillna(mean_Turnover,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baebbd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_Last=data['Last'].mean()\n",
    "data['Last'].fillna(mean_Last,inplace=True)\n",
    "mean_Last=data['Last'].mean()\n",
    "data['Last'].fillna(mean_Last,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d04f60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                                 0\n",
       "Open                                 0\n",
       "High                                 0\n",
       "Low                                  0\n",
       "Last                                 0\n",
       "Close                                0\n",
       "Total Trade Quantity                 0\n",
       "Turnover                             0\n",
       "stock_price_change_in _percentage    0\n",
       "trend                                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b157d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Extraction of Indep and Dep variable \n",
    "x = data.iloc[:,1:2].values ## indep var\n",
    "y = data.iloc[:,5:6].values  #dep|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "718e809f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1235, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bc9c2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1235, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc7f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bc14021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to split data in training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.1,random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18357c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1111, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93fc2263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d16c8a65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model creation --SLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR_model=LinearRegression() # model creation\n",
    "LR_model.fit(x_train, y_train) # model fitting --training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3252c73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[152.95],\n",
       "       [221.  ],\n",
       "       [156.5 ],\n",
       "       [132.95],\n",
       "       [314.65],\n",
       "       [122.5 ],\n",
       "       [164.4 ],\n",
       "       [128.  ],\n",
       "       [143.2 ],\n",
       "       [154.  ],\n",
       "       [171.65],\n",
       "       [121.  ],\n",
       "       [121.6 ],\n",
       "       [158.5 ],\n",
       "       [234.05],\n",
       "       [123.  ],\n",
       "       [243.7 ],\n",
       "       [301.  ],\n",
       "       [156.5 ],\n",
       "       [158.25],\n",
       "       [265.  ],\n",
       "       [138.15],\n",
       "       [142.75],\n",
       "       [142.25],\n",
       "       [173.8 ],\n",
       "       [124.1 ],\n",
       "       [153.4 ],\n",
       "       [132.9 ],\n",
       "       [118.2 ],\n",
       "       [107.3 ],\n",
       "       [140.  ],\n",
       "       [151.1 ],\n",
       "       [107.8 ],\n",
       "       [257.9 ],\n",
       "       [153.65],\n",
       "       [147.45],\n",
       "       [132.9 ],\n",
       "       [271.1 ],\n",
       "       [126.2 ],\n",
       "       [132.9 ],\n",
       "       [152.85],\n",
       "       [122.8 ],\n",
       "       [239.7 ],\n",
       "       [145.7 ],\n",
       "       [124.8 ],\n",
       "       [153.5 ],\n",
       "       [147.75],\n",
       "       [166.3 ],\n",
       "       [278.05],\n",
       "       [120.35],\n",
       "       [241.  ],\n",
       "       [134.7 ],\n",
       "       [159.15],\n",
       "       [120.  ],\n",
       "       [158.8 ],\n",
       "       [135.  ],\n",
       "       [154.5 ],\n",
       "       [157.85],\n",
       "       [139.1 ],\n",
       "       [124.75],\n",
       "       [140.1 ],\n",
       "       [117.8 ],\n",
       "       [270.  ],\n",
       "       [142.7 ],\n",
       "       [141.1 ],\n",
       "       [140.6 ],\n",
       "       [155.4 ],\n",
       "       [223.45],\n",
       "       [155.05],\n",
       "       [147.  ],\n",
       "       [160.45],\n",
       "       [138.5 ],\n",
       "       [139.  ],\n",
       "       [119.5 ],\n",
       "       [120.  ],\n",
       "       [240.7 ],\n",
       "       [105.1 ],\n",
       "       [167.45],\n",
       "       [148.95],\n",
       "       [156.1 ],\n",
       "       [155.45],\n",
       "       [312.  ],\n",
       "       [175.  ],\n",
       "       [167.05],\n",
       "       [112.7 ],\n",
       "       [145.5 ],\n",
       "       [167.9 ],\n",
       "       [134.4 ],\n",
       "       [160.  ],\n",
       "       [155.05],\n",
       "       [280.  ],\n",
       "       [117.75],\n",
       "       [277.  ],\n",
       "       [150.25],\n",
       "       [120.1 ],\n",
       "       [154.45],\n",
       "       [170.5 ],\n",
       "       [305.5 ],\n",
       "       [154.5 ],\n",
       "       [158.  ],\n",
       "       [158.9 ],\n",
       "       [120.  ],\n",
       "       [157.1 ],\n",
       "       [271.55],\n",
       "       [119.5 ],\n",
       "       [154.5 ],\n",
       "       [125.6 ],\n",
       "       [155.55],\n",
       "       [297.4 ],\n",
       "       [275.  ],\n",
       "       [134.  ],\n",
       "       [207.25],\n",
       "       [121.5 ],\n",
       "       [251.  ],\n",
       "       [161.15],\n",
       "       [287.55],\n",
       "       [125.85],\n",
       "       [152.9 ],\n",
       "       [134.45],\n",
       "       [207.95],\n",
       "       [162.25],\n",
       "       [233.3 ],\n",
       "       [158.25],\n",
       "       [143.  ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9100fad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[154.00787989],\n",
       "       [223.27011868],\n",
       "       [153.5095904 ],\n",
       "       [133.22920826],\n",
       "       [317.59631869],\n",
       "       [123.06410271],\n",
       "       [160.88427482],\n",
       "       [128.64494497],\n",
       "       [141.79978744],\n",
       "       [162.72794593],\n",
       "       [175.33466996],\n",
       "       [118.92829996],\n",
       "       [121.12077371],\n",
       "       [157.64539315],\n",
       "       [234.03317161],\n",
       "       [119.32693155],\n",
       "       [242.45426395],\n",
       "       [302.79712091],\n",
       "       [153.90822199],\n",
       "       [159.33957741],\n",
       "       [255.45961958],\n",
       "       [139.25851106],\n",
       "       [143.29465591],\n",
       "       [143.14516906],\n",
       "       [175.63364366],\n",
       "       [127.15007651],\n",
       "       [153.65907725],\n",
       "       [132.78074772],\n",
       "       [118.72898417],\n",
       "       [109.80960234],\n",
       "       [142.74653747],\n",
       "       [154.45634043],\n",
       "       [106.91952331],\n",
       "       [243.50067188],\n",
       "       [154.35668253],\n",
       "       [146.53353758],\n",
       "       [136.31860308],\n",
       "       [278.38093601],\n",
       "       [124.55897117],\n",
       "       [133.22920826],\n",
       "       [152.61266933],\n",
       "       [122.61564217],\n",
       "       [233.38539528],\n",
       "       [145.38747176],\n",
       "       [121.91803689],\n",
       "       [152.66249828],\n",
       "       [148.52669553],\n",
       "       [170.00297245],\n",
       "       [278.33110706],\n",
       "       [119.97470788],\n",
       "       [237.87000067],\n",
       "       [140.00594529],\n",
       "       [161.681538  ],\n",
       "       [120.62248422],\n",
       "       [159.28974846],\n",
       "       [138.16227418],\n",
       "       [156.15052469],\n",
       "       [155.70206415],\n",
       "       [140.80320847],\n",
       "       [125.85452384],\n",
       "       [138.11244524],\n",
       "       [117.98154993],\n",
       "       [276.18846227],\n",
       "       [143.74311645],\n",
       "       [143.94243224],\n",
       "       [137.96295839],\n",
       "       [157.79488   ],\n",
       "       [234.23248741],\n",
       "       [155.50274835],\n",
       "       [147.87891919],\n",
       "       [161.7811959 ],\n",
       "       [144.19157698],\n",
       "       [139.5076558 ],\n",
       "       [119.52624735],\n",
       "       [119.2771026 ],\n",
       "       [236.42496115],\n",
       "       [106.72020751],\n",
       "       [167.8104987 ],\n",
       "       [147.4802876 ],\n",
       "       [153.45976146],\n",
       "       [156.00103784],\n",
       "       [312.26462117],\n",
       "       [169.70399875],\n",
       "       [170.00297245],\n",
       "       [105.97277328],\n",
       "       [146.98199812],\n",
       "       [169.6541698 ],\n",
       "       [137.16569521],\n",
       "       [158.59214318],\n",
       "       [156.05086679],\n",
       "       [290.9378311 ],\n",
       "       [119.62590524],\n",
       "       [268.11617257],\n",
       "       [152.71232722],\n",
       "       [116.33719462],\n",
       "       [156.89795892],\n",
       "       [171.64732776],\n",
       "       [305.58754204],\n",
       "       [156.10069574],\n",
       "       [160.78461692],\n",
       "       [159.8378669 ],\n",
       "       [120.17402368],\n",
       "       [157.49590631],\n",
       "       [275.49085698],\n",
       "       [119.02795786],\n",
       "       [155.25360361],\n",
       "       [127.89751074],\n",
       "       [154.05770884],\n",
       "       [292.83133115],\n",
       "       [277.93247547],\n",
       "       [134.27561618],\n",
       "       [206.82656558],\n",
       "       [122.21701058],\n",
       "       [254.71218535],\n",
       "       [160.58530113],\n",
       "       [288.54604156],\n",
       "       [124.95760276],\n",
       "       [151.71574825],\n",
       "       [133.22920826],\n",
       "       [206.1289603 ],\n",
       "       [161.83102485],\n",
       "       [236.3751322 ],\n",
       "       [156.69864313],\n",
       "       [143.99226119]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction ----Test dataset\n",
    "y_pred=LR_model.predict(y_test)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a1a6d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[153.45],\n",
       "       [222.95],\n",
       "       [152.95],\n",
       "       [132.6 ],\n",
       "       [317.6 ],\n",
       "       [122.4 ],\n",
       "       [160.35],\n",
       "       [128.  ],\n",
       "       [141.2 ],\n",
       "       [162.2 ],\n",
       "       [174.85],\n",
       "       [118.25],\n",
       "       [120.45],\n",
       "       [157.1 ],\n",
       "       [233.75],\n",
       "       [118.65],\n",
       "       [242.2 ],\n",
       "       [302.75],\n",
       "       [153.35],\n",
       "       [158.8 ],\n",
       "       [255.25],\n",
       "       [138.65],\n",
       "       [142.7 ],\n",
       "       [142.55],\n",
       "       [175.15],\n",
       "       [126.5 ],\n",
       "       [153.1 ],\n",
       "       [132.15],\n",
       "       [118.05],\n",
       "       [109.1 ],\n",
       "       [142.15],\n",
       "       [153.9 ],\n",
       "       [106.2 ],\n",
       "       [243.25],\n",
       "       [153.8 ],\n",
       "       [145.95],\n",
       "       [135.7 ],\n",
       "       [278.25],\n",
       "       [123.9 ],\n",
       "       [132.6 ],\n",
       "       [152.05],\n",
       "       [121.95],\n",
       "       [233.1 ],\n",
       "       [144.8 ],\n",
       "       [121.25],\n",
       "       [152.1 ],\n",
       "       [147.95],\n",
       "       [169.5 ],\n",
       "       [278.2 ],\n",
       "       [119.3 ],\n",
       "       [237.6 ],\n",
       "       [139.4 ],\n",
       "       [161.15],\n",
       "       [119.95],\n",
       "       [158.75],\n",
       "       [137.55],\n",
       "       [155.6 ],\n",
       "       [155.15],\n",
       "       [140.2 ],\n",
       "       [125.2 ],\n",
       "       [137.5 ],\n",
       "       [117.3 ],\n",
       "       [276.05],\n",
       "       [143.15],\n",
       "       [143.35],\n",
       "       [137.35],\n",
       "       [157.25],\n",
       "       [233.95],\n",
       "       [154.95],\n",
       "       [147.3 ],\n",
       "       [161.25],\n",
       "       [143.6 ],\n",
       "       [138.9 ],\n",
       "       [118.85],\n",
       "       [118.6 ],\n",
       "       [236.15],\n",
       "       [106.  ],\n",
       "       [167.3 ],\n",
       "       [146.9 ],\n",
       "       [152.9 ],\n",
       "       [155.45],\n",
       "       [312.25],\n",
       "       [169.2 ],\n",
       "       [169.5 ],\n",
       "       [105.25],\n",
       "       [146.4 ],\n",
       "       [169.15],\n",
       "       [136.55],\n",
       "       [158.05],\n",
       "       [155.5 ],\n",
       "       [290.85],\n",
       "       [118.95],\n",
       "       [267.95],\n",
       "       [152.15],\n",
       "       [115.65],\n",
       "       [156.35],\n",
       "       [171.15],\n",
       "       [305.55],\n",
       "       [155.55],\n",
       "       [160.25],\n",
       "       [159.3 ],\n",
       "       [119.5 ],\n",
       "       [156.95],\n",
       "       [275.35],\n",
       "       [118.35],\n",
       "       [154.7 ],\n",
       "       [127.25],\n",
       "       [153.5 ],\n",
       "       [292.75],\n",
       "       [277.8 ],\n",
       "       [133.65],\n",
       "       [206.45],\n",
       "       [121.55],\n",
       "       [254.5 ],\n",
       "       [160.05],\n",
       "       [288.45],\n",
       "       [124.3 ],\n",
       "       [151.15],\n",
       "       [132.6 ],\n",
       "       [205.75],\n",
       "       [161.3 ],\n",
       "       [236.1 ],\n",
       "       [156.15],\n",
       "       [143.4 ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4d511a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8613c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aaea5bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[152.95],\n",
       "       [221.  ],\n",
       "       [156.5 ],\n",
       "       [132.95],\n",
       "       [314.65],\n",
       "       [122.5 ],\n",
       "       [164.4 ],\n",
       "       [128.  ],\n",
       "       [143.2 ],\n",
       "       [154.  ],\n",
       "       [171.65],\n",
       "       [121.  ],\n",
       "       [121.6 ],\n",
       "       [158.5 ],\n",
       "       [234.05],\n",
       "       [123.  ],\n",
       "       [243.7 ],\n",
       "       [301.  ],\n",
       "       [156.5 ],\n",
       "       [158.25],\n",
       "       [265.  ],\n",
       "       [138.15],\n",
       "       [142.75],\n",
       "       [142.25],\n",
       "       [173.8 ],\n",
       "       [124.1 ],\n",
       "       [153.4 ],\n",
       "       [132.9 ],\n",
       "       [118.2 ],\n",
       "       [107.3 ],\n",
       "       [140.  ],\n",
       "       [151.1 ],\n",
       "       [107.8 ],\n",
       "       [257.9 ],\n",
       "       [153.65],\n",
       "       [147.45],\n",
       "       [132.9 ],\n",
       "       [271.1 ],\n",
       "       [126.2 ],\n",
       "       [132.9 ],\n",
       "       [152.85],\n",
       "       [122.8 ],\n",
       "       [239.7 ],\n",
       "       [145.7 ],\n",
       "       [124.8 ],\n",
       "       [153.5 ],\n",
       "       [147.75],\n",
       "       [166.3 ],\n",
       "       [278.05],\n",
       "       [120.35],\n",
       "       [241.  ],\n",
       "       [134.7 ],\n",
       "       [159.15],\n",
       "       [120.  ],\n",
       "       [158.8 ],\n",
       "       [135.  ],\n",
       "       [154.5 ],\n",
       "       [157.85],\n",
       "       [139.1 ],\n",
       "       [124.75],\n",
       "       [140.1 ],\n",
       "       [117.8 ],\n",
       "       [270.  ],\n",
       "       [142.7 ],\n",
       "       [141.1 ],\n",
       "       [140.6 ],\n",
       "       [155.4 ],\n",
       "       [223.45],\n",
       "       [155.05],\n",
       "       [147.  ],\n",
       "       [160.45],\n",
       "       [138.5 ],\n",
       "       [139.  ],\n",
       "       [119.5 ],\n",
       "       [120.  ],\n",
       "       [240.7 ],\n",
       "       [105.1 ],\n",
       "       [167.45],\n",
       "       [148.95],\n",
       "       [156.1 ],\n",
       "       [155.45],\n",
       "       [312.  ],\n",
       "       [175.  ],\n",
       "       [167.05],\n",
       "       [112.7 ],\n",
       "       [145.5 ],\n",
       "       [167.9 ],\n",
       "       [134.4 ],\n",
       "       [160.  ],\n",
       "       [155.05],\n",
       "       [280.  ],\n",
       "       [117.75],\n",
       "       [277.  ],\n",
       "       [150.25],\n",
       "       [120.1 ],\n",
       "       [154.45],\n",
       "       [170.5 ],\n",
       "       [305.5 ],\n",
       "       [154.5 ],\n",
       "       [158.  ],\n",
       "       [158.9 ],\n",
       "       [120.  ],\n",
       "       [157.1 ],\n",
       "       [271.55],\n",
       "       [119.5 ],\n",
       "       [154.5 ],\n",
       "       [125.6 ],\n",
       "       [155.55],\n",
       "       [297.4 ],\n",
       "       [275.  ],\n",
       "       [134.  ],\n",
       "       [207.25],\n",
       "       [121.5 ],\n",
       "       [251.  ],\n",
       "       [161.15],\n",
       "       [287.55],\n",
       "       [125.85],\n",
       "       [152.9 ],\n",
       "       [134.45],\n",
       "       [207.95],\n",
       "       [162.25],\n",
       "       [233.3 ],\n",
       "       [158.25],\n",
       "       [143.  ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4418836a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.98956633448769"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evluation \n",
    "# performance measure\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30ae4486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter open_price-->\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SHAURY~1\\AppData\\Local\\Temp/ipykernel_9988/3916445165.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclose_price\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'enter open_price-->'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'closing price is'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLR_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclose_price\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "close_price=float(input('enter open_price-->'))\n",
    "print('closing price is', LR_model.predict([[close_price]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a78922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting closing price with high price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d93bee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of indep and dep var\n",
    "X=data.iloc[:, 2:3].values\n",
    "Y=data.iloc[:, 5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6586b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ed126863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model creation --SLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR_model=LinearRegression() # model creation\n",
    "LR_model.fit(X_train, Y_train) # model fitting --training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "bbf5167b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[152.88594124],\n",
       "       [221.11368351],\n",
       "       [154.99203809],\n",
       "       [132.36374166],\n",
       "       [313.87990308],\n",
       "       [122.61692133],\n",
       "       [165.66945935],\n",
       "       [127.56379999],\n",
       "       [141.816688  ],\n",
       "       [161.75113962],\n",
       "       [174.73057372],\n",
       "       [119.87409752],\n",
       "       [121.14755143],\n",
       "       [158.32260986],\n",
       "       [232.32987373],\n",
       "       [123.98833324],\n",
       "       [243.15423198],\n",
       "       [301.29230095],\n",
       "       [155.77570204],\n",
       "       [159.54708477],\n",
       "       [261.17850273],\n",
       "       [137.26164132],\n",
       "       [141.27791904],\n",
       "       [141.62077202],\n",
       "       [174.9754687 ],\n",
       "       [126.0454511 ],\n",
       "       [152.73900425],\n",
       "       [132.26578366],\n",
       "       [118.20881164],\n",
       "       [108.80484429],\n",
       "       [142.64933094],\n",
       "       [152.39615127],\n",
       "       [107.04160041],\n",
       "       [253.83165324],\n",
       "       [154.50224812],\n",
       "       [146.91050365],\n",
       "       [134.81269149],\n",
       "       [275.28445375],\n",
       "       [125.60464013],\n",
       "       [131.7759937 ],\n",
       "       [150.92678137],\n",
       "       [122.86181632],\n",
       "       [239.52978623],\n",
       "       [143.92278486],\n",
       "       [123.64548026],\n",
       "       [152.54308826],\n",
       "       [148.57578953],\n",
       "       [168.46126216],\n",
       "       [276.75382365],\n",
       "       [119.92307652],\n",
       "       [237.81552135],\n",
       "       [140.20038111],\n",
       "       [160.03687474],\n",
       "       [120.70674047],\n",
       "       [157.83281989],\n",
       "       [137.26164132],\n",
       "       [155.67774404],\n",
       "       [155.92263902],\n",
       "       [139.26978018],\n",
       "       [124.28220722],\n",
       "       [140.20038111],\n",
       "       [117.57208468],\n",
       "       [272.19877697],\n",
       "       [143.04116292],\n",
       "       [142.45341496],\n",
       "       [139.51467516],\n",
       "       [155.62876505],\n",
       "       [233.06455868],\n",
       "       [154.50224812],\n",
       "       [146.66560867],\n",
       "       [161.21237066],\n",
       "       [144.02074285],\n",
       "       [138.77999021],\n",
       "       [118.55166461],\n",
       "       [118.99247558],\n",
       "       [240.21549218],\n",
       "       [107.43343239],\n",
       "       [167.23678724],\n",
       "       [148.03702057],\n",
       "       [154.7961221 ],\n",
       "       [159.25321079],\n",
       "       [308.29629746],\n",
       "       [172.62447687],\n",
       "       [170.46940102],\n",
       "       [114.63334489],\n",
       "       [147.84110458],\n",
       "       [168.36330416],\n",
       "       [137.21266232],\n",
       "       [158.12669387],\n",
       "       [153.91450016],\n",
       "       [289.14550979],\n",
       "       [117.96391666],\n",
       "       [272.59060894],\n",
       "       [151.66146632],\n",
       "       [120.51082448],\n",
       "       [154.99203809],\n",
       "       [169.93063205],\n",
       "       [303.69227178],\n",
       "       [155.38387006],\n",
       "       [158.91035782],\n",
       "       [158.17567287],\n",
       "       [119.72716053],\n",
       "       [156.06957601],\n",
       "       [272.39469295],\n",
       "       [118.84553859],\n",
       "       [154.50224812],\n",
       "       [127.22094701],\n",
       "       [154.25735314],\n",
       "       [295.07196838],\n",
       "       [277.09667663],\n",
       "       [133.44127958],\n",
       "       [207.44854345],\n",
       "       [122.07815237],\n",
       "       [251.4806614 ],\n",
       "       [161.31032865],\n",
       "       [285.17821107],\n",
       "       [125.60464013],\n",
       "       [151.22065535],\n",
       "       [133.04944761],\n",
       "       [206.22406854],\n",
       "       [161.75113962],\n",
       "       [233.11353768],\n",
       "       [157.93077789],\n",
       "       [144.21665884],\n",
       "       [126.97605203],\n",
       "       [141.08200305],\n",
       "       [208.2322074 ],\n",
       "       [148.77170552],\n",
       "       [125.40872414],\n",
       "       [123.0577323 ],\n",
       "       [148.47783154],\n",
       "       [150.19209642],\n",
       "       [137.06572533],\n",
       "       [127.95563196],\n",
       "       [153.3757312 ],\n",
       "       [152.24921428],\n",
       "       [128.98419089],\n",
       "       [146.61662967],\n",
       "       [208.33016539],\n",
       "       [293.70055648],\n",
       "       [147.54723061],\n",
       "       [152.54308826],\n",
       "       [153.03287823],\n",
       "       [267.54577229],\n",
       "       [170.61633801],\n",
       "       [123.64548026],\n",
       "       [151.07371836],\n",
       "       [130.50253979],\n",
       "       [131.09028775],\n",
       "       [194.56706735],\n",
       "       [105.52325152],\n",
       "       [160.28176972],\n",
       "       [117.62106368],\n",
       "       [148.33089455],\n",
       "       [160.77155969],\n",
       "       [151.85738231],\n",
       "       [152.78798324],\n",
       "       [133.2453636 ],\n",
       "       [152.54308826],\n",
       "       [154.35531113],\n",
       "       [124.13527023],\n",
       "       [204.16695068],\n",
       "       [139.51467516],\n",
       "       [144.21665884],\n",
       "       [142.64933094],\n",
       "       [154.01245816],\n",
       "       [156.90221896],\n",
       "       [193.93034039],\n",
       "       [234.82780256],\n",
       "       [118.11085365],\n",
       "       [145.58807074],\n",
       "       [152.83696224],\n",
       "       [145.00032278],\n",
       "       [142.40443596],\n",
       "       [226.74626812],\n",
       "       [285.91289602],\n",
       "       [119.09043358],\n",
       "       [123.93935424],\n",
       "       [134.22494353],\n",
       "       [149.1145585 ],\n",
       "       [123.64548026],\n",
       "       [170.56735901],\n",
       "       [155.77570204],\n",
       "       [140.54323409],\n",
       "       [156.41242899],\n",
       "       [117.76800067],\n",
       "       [245.30930783],\n",
       "       [146.1758187 ],\n",
       "       [160.5756437 ],\n",
       "       [142.15954098],\n",
       "       [150.04515943],\n",
       "       [140.15140212],\n",
       "       [154.99203809],\n",
       "       [144.02074285],\n",
       "       [144.60849081],\n",
       "       [145.04930178],\n",
       "       [169.48982108],\n",
       "       [245.7501188 ],\n",
       "       [139.22080118],\n",
       "       [124.5760812 ],\n",
       "       [146.51867168],\n",
       "       [160.72258069],\n",
       "       [156.16753401],\n",
       "       [143.48197389],\n",
       "       [271.02328105],\n",
       "       [158.81239982],\n",
       "       [235.6604455 ],\n",
       "       [127.80869497],\n",
       "       [125.11485016],\n",
       "       [145.93092372],\n",
       "       [227.87278504],\n",
       "       [118.55166461],\n",
       "       [138.04530526],\n",
       "       [116.44556776],\n",
       "       [120.80469846],\n",
       "       [118.89451759],\n",
       "       [147.5962096 ],\n",
       "       [132.46169965],\n",
       "       [203.97103469],\n",
       "       [134.42085951],\n",
       "       [133.68617457],\n",
       "       [156.265492  ],\n",
       "       [135.35146045],\n",
       "       [152.54308826],\n",
       "       [262.69685163],\n",
       "       [124.13527023],\n",
       "       [162.82867755],\n",
       "       [233.35843266],\n",
       "       [133.34332159],\n",
       "       [276.70484465],\n",
       "       [155.33489107],\n",
       "       [176.24892262],\n",
       "       [133.00046861],\n",
       "       [154.55122712],\n",
       "       [243.15423198],\n",
       "       [141.47383503],\n",
       "       [279.88847943],\n",
       "       [133.44127958],\n",
       "       [284.29658913],\n",
       "       [129.18010688],\n",
       "       [151.56350833],\n",
       "       [162.63276156],\n",
       "       [136.38001938],\n",
       "       [134.6657545 ],\n",
       "       [147.74314659],\n",
       "       [151.80840331],\n",
       "       [142.40443596]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction ----Test dataset\n",
    "Y_pred=LR_model.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ea052e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[153.45],\n",
       "       [222.95],\n",
       "       [152.95],\n",
       "       [132.6 ],\n",
       "       [317.6 ],\n",
       "       [122.4 ],\n",
       "       [160.35],\n",
       "       [128.  ],\n",
       "       [141.2 ],\n",
       "       [162.2 ],\n",
       "       [174.85],\n",
       "       [118.25],\n",
       "       [120.45],\n",
       "       [157.1 ],\n",
       "       [233.75],\n",
       "       [118.65],\n",
       "       [242.2 ],\n",
       "       [302.75],\n",
       "       [153.35],\n",
       "       [158.8 ],\n",
       "       [255.25],\n",
       "       [138.65],\n",
       "       [142.7 ],\n",
       "       [142.55],\n",
       "       [175.15],\n",
       "       [126.5 ],\n",
       "       [153.1 ],\n",
       "       [132.15],\n",
       "       [118.05],\n",
       "       [109.1 ],\n",
       "       [142.15],\n",
       "       [153.9 ],\n",
       "       [106.2 ],\n",
       "       [243.25],\n",
       "       [153.8 ],\n",
       "       [145.95],\n",
       "       [135.7 ],\n",
       "       [278.25],\n",
       "       [123.9 ],\n",
       "       [132.6 ],\n",
       "       [152.05],\n",
       "       [121.95],\n",
       "       [233.1 ],\n",
       "       [144.8 ],\n",
       "       [121.25],\n",
       "       [152.1 ],\n",
       "       [147.95],\n",
       "       [169.5 ],\n",
       "       [278.2 ],\n",
       "       [119.3 ],\n",
       "       [237.6 ],\n",
       "       [139.4 ],\n",
       "       [161.15],\n",
       "       [119.95],\n",
       "       [158.75],\n",
       "       [137.55],\n",
       "       [155.6 ],\n",
       "       [155.15],\n",
       "       [140.2 ],\n",
       "       [125.2 ],\n",
       "       [137.5 ],\n",
       "       [117.3 ],\n",
       "       [276.05],\n",
       "       [143.15],\n",
       "       [143.35],\n",
       "       [137.35],\n",
       "       [157.25],\n",
       "       [233.95],\n",
       "       [154.95],\n",
       "       [147.3 ],\n",
       "       [161.25],\n",
       "       [143.6 ],\n",
       "       [138.9 ],\n",
       "       [118.85],\n",
       "       [118.6 ],\n",
       "       [236.15],\n",
       "       [106.  ],\n",
       "       [167.3 ],\n",
       "       [146.9 ],\n",
       "       [152.9 ],\n",
       "       [155.45],\n",
       "       [312.25],\n",
       "       [169.2 ],\n",
       "       [169.5 ],\n",
       "       [105.25],\n",
       "       [146.4 ],\n",
       "       [169.15],\n",
       "       [136.55],\n",
       "       [158.05],\n",
       "       [155.5 ],\n",
       "       [290.85],\n",
       "       [118.95],\n",
       "       [267.95],\n",
       "       [152.15],\n",
       "       [115.65],\n",
       "       [156.35],\n",
       "       [171.15],\n",
       "       [305.55],\n",
       "       [155.55],\n",
       "       [160.25],\n",
       "       [159.3 ],\n",
       "       [119.5 ],\n",
       "       [156.95],\n",
       "       [275.35],\n",
       "       [118.35],\n",
       "       [154.7 ],\n",
       "       [127.25],\n",
       "       [153.5 ],\n",
       "       [292.75],\n",
       "       [277.8 ],\n",
       "       [133.65],\n",
       "       [206.45],\n",
       "       [121.55],\n",
       "       [254.5 ],\n",
       "       [160.05],\n",
       "       [288.45],\n",
       "       [124.3 ],\n",
       "       [151.15],\n",
       "       [132.6 ],\n",
       "       [205.75],\n",
       "       [161.3 ],\n",
       "       [236.1 ],\n",
       "       [156.15],\n",
       "       [143.4 ],\n",
       "       [127.9 ],\n",
       "       [140.2 ],\n",
       "       [208.3 ],\n",
       "       [147.25],\n",
       "       [125.45],\n",
       "       [120.75],\n",
       "       [148.2 ],\n",
       "       [151.45],\n",
       "       [136.6 ],\n",
       "       [127.8 ],\n",
       "       [154.4 ],\n",
       "       [151.6 ],\n",
       "       [128.65],\n",
       "       [145.9 ],\n",
       "       [206.8 ],\n",
       "       [287.8 ],\n",
       "       [147.5 ],\n",
       "       [153.7 ],\n",
       "       [151.15],\n",
       "       [270.7 ],\n",
       "       [171.1 ],\n",
       "       [123.35],\n",
       "       [151.9 ],\n",
       "       [126.85],\n",
       "       [128.  ],\n",
       "       [196.7 ],\n",
       "       [104.55],\n",
       "       [159.35],\n",
       "       [117.  ],\n",
       "       [149.15],\n",
       "       [162.  ],\n",
       "       [152.2 ],\n",
       "       [152.65],\n",
       "       [133.85],\n",
       "       [152.95],\n",
       "       [154.85],\n",
       "       [124.45],\n",
       "       [205.95],\n",
       "       [137.75],\n",
       "       [145.15],\n",
       "       [141.9 ],\n",
       "       [154.05],\n",
       "       [157.45],\n",
       "       [193.85],\n",
       "       [237.55],\n",
       "       [118.85],\n",
       "       [146.35],\n",
       "       [154.45],\n",
       "       [143.65],\n",
       "       [142.75],\n",
       "       [226.8 ],\n",
       "       [280.2 ],\n",
       "       [119.35],\n",
       "       [123.25],\n",
       "       [135.3 ],\n",
       "       [149.45],\n",
       "       [121.4 ],\n",
       "       [168.6 ],\n",
       "       [156.4 ],\n",
       "       [137.1 ],\n",
       "       [157.55],\n",
       "       [117.7 ],\n",
       "       [246.3 ],\n",
       "       [137.  ],\n",
       "       [161.6 ],\n",
       "       [143.35],\n",
       "       [151.1 ],\n",
       "       [141.25],\n",
       "       [154.9 ],\n",
       "       [141.65],\n",
       "       [144.6 ],\n",
       "       [141.95],\n",
       "       [164.45],\n",
       "       [246.9 ],\n",
       "       [139.6 ],\n",
       "       [124.45],\n",
       "       [147.65],\n",
       "       [158.05],\n",
       "       [157.45],\n",
       "       [144.05],\n",
       "       [269.8 ],\n",
       "       [159.8 ],\n",
       "       [237.05],\n",
       "       [128.35],\n",
       "       [124.4 ],\n",
       "       [146.2 ],\n",
       "       [227.8 ],\n",
       "       [117.3 ],\n",
       "       [138.5 ],\n",
       "       [115.1 ],\n",
       "       [120.95],\n",
       "       [119.6 ],\n",
       "       [147.45],\n",
       "       [133.45],\n",
       "       [198.6 ],\n",
       "       [133.8 ],\n",
       "       [133.2 ],\n",
       "       [156.95],\n",
       "       [135.6 ],\n",
       "       [151.25],\n",
       "       [264.5 ],\n",
       "       [124.75],\n",
       "       [162.55],\n",
       "       [234.6 ],\n",
       "       [133.35],\n",
       "       [278.5 ],\n",
       "       [153.85],\n",
       "       [173.75],\n",
       "       [131.15],\n",
       "       [156.05],\n",
       "       [245.15],\n",
       "       [141.6 ],\n",
       "       [281.  ],\n",
       "       [132.95],\n",
       "       [281.95],\n",
       "       [130.1 ],\n",
       "       [149.45],\n",
       "       [161.1 ],\n",
       "       [134.95],\n",
       "       [131.35],\n",
       "       [149.05],\n",
       "       [149.95],\n",
       "       [143.65]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0b38650a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.81656752501006"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evluation \n",
    "# performance measure\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y_test, Y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6c11da16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter high price>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SHAURY~1\\AppData\\Local\\Temp/ipykernel_9988/126285358.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mClose_price\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'enter high price>'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The salary for Year of Exp-->'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLR_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mClose_price\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "Close_price=float(input('enter high price>'))\n",
    "print('The salary for Year of Exp-->', LR_model.predict([[Close_price]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3ab09742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted \n",
    "# Extraction of indep and dep var\n",
    "X=data.iloc[:, 3:4].values\n",
    "Y=data.iloc[:, 5:6].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e926c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fa3b7159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model creation --SLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR_model=LinearRegression() # model creation\n",
    "LR_model.fit(X_train, Y_train) # model fitting --training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e99eeb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[153.10408404],\n",
       "       [222.26379763],\n",
       "       [153.9171299 ],\n",
       "       [134.04832166],\n",
       "       [316.88200975],\n",
       "       [123.52954083],\n",
       "       [161.23454266],\n",
       "       [127.89966234],\n",
       "       [142.89019541],\n",
       "       [156.10219066],\n",
       "       [168.39950931],\n",
       "       [119.51512689],\n",
       "       [119.87083446],\n",
       "       [158.33806677],\n",
       "       [233.54480895],\n",
       "       [118.7528964 ],\n",
       "       [244.41929735],\n",
       "       [304.17816816],\n",
       "       [154.8318065 ],\n",
       "       [160.16741996],\n",
       "       [257.22476967],\n",
       "       [139.07904293],\n",
       "       [143.70324127],\n",
       "       [143.39834907],\n",
       "       [176.12344499],\n",
       "       [124.95237109],\n",
       "       [154.069576  ],\n",
       "       [132.82875287],\n",
       "       [119.36268079],\n",
       "       [108.3357463 ],\n",
       "       [141.46736515],\n",
       "       [153.15489941],\n",
       "       [103.76236333],\n",
       "       [245.63886614],\n",
       "       [155.59403699],\n",
       "       [146.49808642],\n",
       "       [134.35321386],\n",
       "       [275.11177862],\n",
       "       [124.49503279],\n",
       "       [133.33690654],\n",
       "       [152.44348428],\n",
       "       [123.07220254],\n",
       "       [231.91871723],\n",
       "       [144.16057957],\n",
       "       [122.30997204],\n",
       "       [153.81549917],\n",
       "       [149.64863913],\n",
       "       [168.60277077],\n",
       "       [277.24602401],\n",
       "       [120.12491129],\n",
       "       [238.72797632],\n",
       "       [136.43664388],\n",
       "       [159.0494819 ],\n",
       "       [120.48061885],\n",
       "       [159.8117124 ],\n",
       "       [135.77604412],\n",
       "       [155.39077553],\n",
       "       [156.86442115],\n",
       "       [140.19698099],\n",
       "       [126.17193988],\n",
       "       [138.72333537],\n",
       "       [117.5333276 ],\n",
       "       [273.68894836],\n",
       "       [144.46547176],\n",
       "       [141.97551881],\n",
       "       [138.31681244],\n",
       "       [155.74648309],\n",
       "       [226.5322884 ],\n",
       "       [154.9842526 ],\n",
       "       [147.36194765],\n",
       "       [162.65737291],\n",
       "       [140.09535026],\n",
       "       [140.19698099],\n",
       "       [119.51512689],\n",
       "       [119.66757299],\n",
       "       [238.06737656],\n",
       "       [106.40476238],\n",
       "       [167.78972491],\n",
       "       [148.07336277],\n",
       "       [153.96794527],\n",
       "       [151.27473085],\n",
       "       [311.85128848],\n",
       "       [170.68620079],\n",
       "       [169.36500127],\n",
       "       [103.66073259],\n",
       "       [147.46357838],\n",
       "       [169.1617398 ],\n",
       "       [135.92849022],\n",
       "       [157.47420555],\n",
       "       [155.84811382],\n",
       "       [279.17700793],\n",
       "       [118.7528964 ],\n",
       "       [266.87968927],\n",
       "       [152.29103818],\n",
       "       [116.36457418],\n",
       "       [155.74648309],\n",
       "       [171.55006202],\n",
       "       [307.02382868],\n",
       "       [155.49240626],\n",
       "       [159.91334313],\n",
       "       [158.18562068],\n",
       "       [120.68388032],\n",
       "       [156.71197505],\n",
       "       [273.12997933],\n",
       "       [119.56594226],\n",
       "       [155.44159089],\n",
       "       [126.32438598],\n",
       "       [155.18751406],\n",
       "       [293.7102027 ],\n",
       "       [277.04276254],\n",
       "       [134.50565996],\n",
       "       [207.93386432],\n",
       "       [121.85263374],\n",
       "       [250.92366424],\n",
       "       [161.18372729],\n",
       "       [289.28926583],\n",
       "       [125.00318646],\n",
       "       [152.54511501],\n",
       "       [133.18446044],\n",
       "       [207.73060285],\n",
       "       [161.84432705],\n",
       "       [235.37416214],\n",
       "       [157.67746701],\n",
       "       [144.36384103],\n",
       "       [128.2553699 ],\n",
       "       [137.14805901],\n",
       "       [210.62707874],\n",
       "       [148.17499351],\n",
       "       [126.73090891],\n",
       "       [121.64937228],\n",
       "       [149.49619303],\n",
       "       [151.83369988],\n",
       "       [137.80865877],\n",
       "       [128.30618527],\n",
       "       [153.6122377 ],\n",
       "       [153.45979161],\n",
       "       [129.37330796],\n",
       "       [147.05705545],\n",
       "       [208.54364872],\n",
       "       [290.91535755],\n",
       "       [147.87010131],\n",
       "       [151.52880768],\n",
       "       [151.83369988],\n",
       "       [266.87968927],\n",
       "       [170.33049323],\n",
       "       [123.68198693],\n",
       "       [152.74837648],\n",
       "       [127.64558551],\n",
       "       [129.1700465 ],\n",
       "       [196.0430686 ],\n",
       "       [103.76236333],\n",
       "       [159.76089703],\n",
       "       [117.78740444],\n",
       "       [148.37825497],\n",
       "       [160.42149679],\n",
       "       [152.18940745],\n",
       "       [153.71386844],\n",
       "       [132.06652238],\n",
       "       [153.71386844],\n",
       "       [156.00055992],\n",
       "       [125.40970939],\n",
       "       [197.36426812],\n",
       "       [137.45295121],\n",
       "       [144.92281006],\n",
       "       [143.09345687],\n",
       "       [154.069576  ],\n",
       "       [159.0494819 ],\n",
       "       [184.05064214],\n",
       "       [238.42308412],\n",
       "       [116.97435857],\n",
       "       [143.39834907],\n",
       "       [153.56142234],\n",
       "       [145.02444079],\n",
       "       [144.1097642 ],\n",
       "       [225.71924254],\n",
       "       [282.42919137],\n",
       "       [120.37898812],\n",
       "       [124.29177133],\n",
       "       [133.64179873],\n",
       "       [150.56331572],\n",
       "       [121.03958788],\n",
       "       [166.36689466],\n",
       "       [155.08588333],\n",
       "       [138.57088927],\n",
       "       [157.22012871],\n",
       "       [118.49881957],\n",
       "       [245.43560468],\n",
       "       [136.13175168],\n",
       "       [159.0494819 ],\n",
       "       [142.43285711],\n",
       "       [150.81739256],\n",
       "       [140.60350392],\n",
       "       [154.88262186],\n",
       "       [141.97551881],\n",
       "       [146.09156349],\n",
       "       [143.14427224],\n",
       "       [165.90955636],\n",
       "       [245.02908175],\n",
       "       [138.01192024],\n",
       "       [124.90155572],\n",
       "       [146.95542471],\n",
       "       [158.49051287],\n",
       "       [153.05326868],\n",
       "       [145.38014836],\n",
       "       [271.40225688],\n",
       "       [157.37257481],\n",
       "       [234.40867018],\n",
       "       [129.11923113],\n",
       "       [120.42980349],\n",
       "       [147.76847058],\n",
       "       [229.63202575],\n",
       "       [116.61865101],\n",
       "       [138.67252   ],\n",
       "       [115.95805125],\n",
       "       [118.49881957],\n",
       "       [118.34637347],\n",
       "       [148.73396254],\n",
       "       [132.93038361],\n",
       "       [199.44769814],\n",
       "       [132.77793751],\n",
       "       [134.25158313],\n",
       "       [157.88072848],\n",
       "       [136.79235145],\n",
       "       [152.64674574],\n",
       "       [263.93239802],\n",
       "       [125.56215549],\n",
       "       [162.70818828],\n",
       "       [231.25811747],\n",
       "       [133.59098337],\n",
       "       [279.32945403],\n",
       "       [154.78099113],\n",
       "       [175.46284523],\n",
       "       [132.26978384],\n",
       "       [155.23832943],\n",
       "       [246.55354274],\n",
       "       [142.89019541],\n",
       "       [266.57479707],\n",
       "       [132.98119897],\n",
       "       [285.07159042],\n",
       "       [129.0176004 ],\n",
       "       [148.4798857 ],\n",
       "       [162.86063438],\n",
       "       [136.28419778],\n",
       "       [132.52386067],\n",
       "       [150.10597743],\n",
       "       [151.02065402],\n",
       "       [145.12607153]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction ----Test dataset\n",
    "Y_pred=LR_model.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3bc171ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.8046547407898"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evluation \n",
    "# performance measure\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y_test, Y_pred)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9960cedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a low price-->\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SHAURY~1\\AppData\\Local\\Temp/ipykernel_9988/2383557750.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mClose_price\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'enter a low price-->'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The closing price is '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLR_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mClose_price\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "Close_price=float(input('enter a low price-->'))\n",
    "print('The closing price is ', LR_model.predict([[Close_price]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7d076008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting closing price last price\n",
    "# Extraction of indep and dep var\n",
    "X=data.iloc[:, 4:5].values\n",
    "Y=data.iloc[:, 5:6].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a0528381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1235, 1)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ef43ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8db362a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model creation --SLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR_model=LinearRegression() # model creation\n",
    "LR_model.fit(X_train, Y_train) # model fitting --training dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f8248ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[153.03994982],\n",
       "       [222.26162273],\n",
       "       [154.0755573 ],\n",
       "       [133.73743879],\n",
       "       [316.9134893 ],\n",
       "       [123.27839793],\n",
       "       [161.81234349],\n",
       "       [127.75682795],\n",
       "       [142.71172423],\n",
       "       [156.66344023],\n",
       "       [169.21616366],\n",
       "       [119.46437366],\n",
       "       [119.93219843],\n",
       "       [158.32040977],\n",
       "       [233.6145942 ],\n",
       "       [119.3292792 ],\n",
       "       [244.48185835],\n",
       "       [304.16138656],\n",
       "       [154.95356544],\n",
       "       [160.03069495],\n",
       "       [258.14488465],\n",
       "       [138.7719114 ],\n",
       "       [143.3394004 ],\n",
       "       [143.10226621],\n",
       "       [175.9613913 ],\n",
       "       [124.93860416],\n",
       "       [153.86769336],\n",
       "       [132.67335224],\n",
       "       [119.06858515],\n",
       "       [108.1984761 ],\n",
       "       [141.49457024],\n",
       "       [152.97869102],\n",
       "       [104.06736301],\n",
       "       [247.12841687],\n",
       "       [155.38979646],\n",
       "       [146.51637716],\n",
       "       [134.27811438],\n",
       "       [275.33829014],\n",
       "       [124.54992704],\n",
       "       [133.05569336],\n",
       "       [152.24438847],\n",
       "       [122.91994922],\n",
       "       [233.18347552],\n",
       "       [144.11372378],\n",
       "       [122.40526651],\n",
       "       [153.62894552],\n",
       "       [149.43076842],\n",
       "       [168.5344746 ],\n",
       "       [277.53107243],\n",
       "       [119.97844614],\n",
       "       [238.8940928 ],\n",
       "       [136.73654429],\n",
       "       [159.14651937],\n",
       "       [120.36515688],\n",
       "       [159.54324747],\n",
       "       [135.8399887 ],\n",
       "       [155.3711335 ],\n",
       "       [156.75890526],\n",
       "       [139.99003145],\n",
       "       [125.8065419 ],\n",
       "       [138.85204379],\n",
       "       [117.40798092],\n",
       "       [273.73047087],\n",
       "       [144.1962721 ],\n",
       "       [141.93969018],\n",
       "       [138.43667463],\n",
       "       [155.69622643],\n",
       "       [227.36947055],\n",
       "       [154.90127371],\n",
       "       [147.2213627 ],\n",
       "       [162.42605887],\n",
       "       [140.42789629],\n",
       "       [139.9315473 ],\n",
       "       [119.2737197 ],\n",
       "       [119.4687199 ],\n",
       "       [238.59002081],\n",
       "       [106.31858448],\n",
       "       [167.72447633],\n",
       "       [148.04300746],\n",
       "       [154.08639551],\n",
       "       [152.2548052 ],\n",
       "       [311.86875583],\n",
       "       [171.03705145],\n",
       "       [169.44055592],\n",
       "       [104.97542299],\n",
       "       [147.40303251],\n",
       "       [169.04788689],\n",
       "       [135.94988136],\n",
       "       [157.59313918],\n",
       "       [155.57916452],\n",
       "       [280.66029873],\n",
       "       [118.50289821],\n",
       "       [268.09010892],\n",
       "       [152.12745146],\n",
       "       [116.79637082],\n",
       "       [155.59836586],\n",
       "       [171.35510323],\n",
       "       [307.00843105],\n",
       "       [155.42527301],\n",
       "       [159.7323893 ],\n",
       "       [158.18286371],\n",
       "       [120.42877845],\n",
       "       [156.62423538],\n",
       "       [273.31208664],\n",
       "       [119.35102907],\n",
       "       [155.28097747],\n",
       "       [126.29555147],\n",
       "       [155.06193968],\n",
       "       [294.33044924],\n",
       "       [277.31368116],\n",
       "       [134.28254795],\n",
       "       [207.98192834],\n",
       "       [121.74443291],\n",
       "       [251.23366518],\n",
       "       [161.18518713],\n",
       "       [289.12859097],\n",
       "       [124.97877178],\n",
       "       [152.36684531],\n",
       "       [133.11064743],\n",
       "       [207.68574504],\n",
       "       [161.83432429],\n",
       "       [235.26132806],\n",
       "       [157.69948468],\n",
       "       [144.25059885],\n",
       "       [127.98590648],\n",
       "       [137.48506204],\n",
       "       [210.45740286],\n",
       "       [148.25963252],\n",
       "       [126.45817753],\n",
       "       [121.72074644],\n",
       "       [149.3227656 ],\n",
       "       [151.6108992 ],\n",
       "       [137.63953251],\n",
       "       [128.13604169],\n",
       "       [153.51396699],\n",
       "       [153.25146563],\n",
       "       [129.18938365],\n",
       "       [146.95288276],\n",
       "       [208.72002135],\n",
       "       [291.7962002 ],\n",
       "       [147.80127113],\n",
       "       [151.56136813],\n",
       "       [152.00521765],\n",
       "       [267.17436489],\n",
       "       [170.31510424],\n",
       "       [123.56434535],\n",
       "       [152.46679246],\n",
       "       [127.95254749],\n",
       "       [129.35398996],\n",
       "       [195.91602957],\n",
       "       [103.83041927],\n",
       "       [159.7865272 ],\n",
       "       [117.65926796],\n",
       "       [148.29413852],\n",
       "       [160.4119608 ],\n",
       "       [152.10873854],\n",
       "       [153.58253553],\n",
       "       [132.05986179],\n",
       "       [153.49205965],\n",
       "       [155.75685951],\n",
       "       [125.15251853],\n",
       "       [198.17065919],\n",
       "       [137.66251192],\n",
       "       [144.75387679],\n",
       "       [143.01383454],\n",
       "       [153.99951834],\n",
       "       [158.73601305],\n",
       "       [185.18866015],\n",
       "       [238.13094168],\n",
       "       [116.94214591],\n",
       "       [143.56107864],\n",
       "       [153.39011034],\n",
       "       [144.96543467],\n",
       "       [143.82497673],\n",
       "       [225.98957491],\n",
       "       [283.29046835],\n",
       "       [120.07733831],\n",
       "       [124.147595  ],\n",
       "       [133.57773257],\n",
       "       [150.36739171],\n",
       "       [121.17940456],\n",
       "       [166.83061744],\n",
       "       [155.19394562],\n",
       "       [138.77963772],\n",
       "       [157.07218782],\n",
       "       [118.28145558],\n",
       "       [245.61178714],\n",
       "       [137.50610135],\n",
       "       [159.24918962],\n",
       "       [142.30853075],\n",
       "       [150.63396312],\n",
       "       [140.46100857],\n",
       "       [154.9147227 ],\n",
       "       [142.14494334],\n",
       "       [145.8395882 ],\n",
       "       [143.34448936],\n",
       "       [166.43326814],\n",
       "       [245.29552238],\n",
       "       [138.04310839],\n",
       "       [124.74995235],\n",
       "       [146.80083902],\n",
       "       [158.78661929],\n",
       "       [153.31822396],\n",
       "       [145.09377646],\n",
       "       [271.7525577 ],\n",
       "       [157.54505319],\n",
       "       [234.67915678],\n",
       "       [128.86960911],\n",
       "       [120.80510042],\n",
       "       [147.48283565],\n",
       "       [229.54373519],\n",
       "       [116.73492477],\n",
       "       [138.5040401 ],\n",
       "       [115.91729221],\n",
       "       [118.70475859],\n",
       "       [118.25976046],\n",
       "       [148.52377571],\n",
       "       [132.75269664],\n",
       "       [200.24830518],\n",
       "       [132.82589859],\n",
       "       [134.07407218],\n",
       "       [157.65167648],\n",
       "       [136.51990824],\n",
       "       [152.58922272],\n",
       "       [263.97122817],\n",
       "       [125.26399985],\n",
       "       [162.73528847],\n",
       "       [231.78537906],\n",
       "       [133.50665138],\n",
       "       [279.24741273],\n",
       "       [154.86350304],\n",
       "       [175.59814999],\n",
       "       [132.2897486 ],\n",
       "       [155.08200874],\n",
       "       [244.3129349 ],\n",
       "       [142.6446944 ],\n",
       "       [268.32616354],\n",
       "       [132.9893579 ],\n",
       "       [285.40200882],\n",
       "       [128.93295289],\n",
       "       [148.88863665],\n",
       "       [162.84440862],\n",
       "       [136.25754257],\n",
       "       [132.71592939],\n",
       "       [149.75817256],\n",
       "       [151.14197259],\n",
       "       [144.73191948]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction ----Test dataset\n",
    "Y_pred=LR_model.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "088dd81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.83444586273629"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evluation \n",
    "# performance measure\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y_test, Y_pred)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "95765303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low price -->\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SHAURY~1\\AppData\\Local\\Temp/ipykernel_9988/2714845267.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mClose_price\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'low price -->'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Close_price-->'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLR_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mClose_price\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "Close_price=float(input('low price -->'))\n",
    "print('Close_price-->', LR_model.predict([[Close_price]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "64d856fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting close price with the total traded quantity\n",
    "# Extraction of indep and dep var\n",
    "X=data.iloc[:, 6:7].values\n",
    "Y=data.iloc[:, 5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "aa63ad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "bdd10405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model creation --SLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR_model=LinearRegression() # model creation\n",
    "LR_model.fit(X_train, Y_train) # model fitting --training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5bd57685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[177.20356862],\n",
       "       [156.25025793],\n",
       "       [162.52609518],\n",
       "       [153.66332276],\n",
       "       [165.53899502],\n",
       "       [163.34041061],\n",
       "       [167.38487488],\n",
       "       [151.35646486],\n",
       "       [154.29645068],\n",
       "       [200.28083908],\n",
       "       [259.68403905],\n",
       "       [160.50786768],\n",
       "       [157.4065099 ],\n",
       "       [161.8922751 ],\n",
       "       [174.41851771],\n",
       "       [174.30396536],\n",
       "       [162.53123694],\n",
       "       [190.57546169],\n",
       "       [192.24837096],\n",
       "       [166.65198704],\n",
       "       [162.05094766],\n",
       "       [155.43720816],\n",
       "       [150.12755596],\n",
       "       [162.22335463],\n",
       "       [185.20817239],\n",
       "       [153.21537709],\n",
       "       [155.26154804],\n",
       "       [156.98029803],\n",
       "       [149.81153584],\n",
       "       [155.45156552],\n",
       "       [168.20926617],\n",
       "       [159.99606539],\n",
       "       [236.66115253],\n",
       "       [178.22475066],\n",
       "       [162.75208517],\n",
       "       [160.36287022],\n",
       "       [171.11954846],\n",
       "       [174.92903457],\n",
       "       [156.76564957],\n",
       "       [154.87466071],\n",
       "       [155.11589797],\n",
       "       [163.77975373],\n",
       "       [185.82235493],\n",
       "       [162.8386644 ],\n",
       "       [150.45283123],\n",
       "       [158.28322842],\n",
       "       [158.87172196],\n",
       "       [188.67967715],\n",
       "       [174.66844651],\n",
       "       [152.63025535],\n",
       "       [163.47868425],\n",
       "       [168.48094855],\n",
       "       [168.16324747],\n",
       "       [154.79271894],\n",
       "       [162.04980065],\n",
       "       [152.74196985],\n",
       "       [183.74813175],\n",
       "       [150.95487409],\n",
       "       [156.86006997],\n",
       "       [149.04248762],\n",
       "       [163.49548394],\n",
       "       [177.79611624],\n",
       "       [169.60960314],\n",
       "       [153.22575948],\n",
       "       [160.60523471],\n",
       "       [166.52020981],\n",
       "       [173.69982902],\n",
       "       [207.12793511],\n",
       "       [160.35080687],\n",
       "       [162.37415635],\n",
       "       [175.86834406],\n",
       "       [192.70573988],\n",
       "       [155.22709829],\n",
       "       [151.47306403],\n",
       "       [157.74375953],\n",
       "       [220.46091894],\n",
       "       [154.85771269],\n",
       "       [187.51365585],\n",
       "       [212.6886829 ],\n",
       "       [167.20478494],\n",
       "       [176.53654468],\n",
       "       [170.7988711 ],\n",
       "       [198.19013262],\n",
       "       [268.36762135],\n",
       "       [198.68773577],\n",
       "       [167.32306506],\n",
       "       [166.71230377],\n",
       "       [155.84633359],\n",
       "       [155.39074451],\n",
       "       [160.65304314],\n",
       "       [202.52876456],\n",
       "       [149.95870866],\n",
       "       [169.97433149],\n",
       "       [159.29608477],\n",
       "       [163.60509229],\n",
       "       [162.02159022],\n",
       "       [164.86565265],\n",
       "       [176.84467418],\n",
       "       [176.16059345],\n",
       "       [159.13339769],\n",
       "       [157.6443358 ],\n",
       "       [161.739654  ],\n",
       "       [160.57888322],\n",
       "       [159.30579478],\n",
       "       [151.86107859],\n",
       "       [174.72998935],\n",
       "       [171.67543141],\n",
       "       [159.35224855],\n",
       "       [162.42797667],\n",
       "       [189.78297894],\n",
       "       [151.56408296],\n",
       "       [163.69953247],\n",
       "       [157.34708308],\n",
       "       [172.94855941],\n",
       "       [162.65311629],\n",
       "       [186.55524277],\n",
       "       [150.81366372],\n",
       "       [178.53268241],\n",
       "       [156.88732127],\n",
       "       [202.02690957],\n",
       "       [180.78600673],\n",
       "       [167.29376695],\n",
       "       [173.13296051],\n",
       "       [171.47082915],\n",
       "       [151.44277712],\n",
       "       [167.08856152],\n",
       "       [160.40901746],\n",
       "       [155.7233369 ],\n",
       "       [148.48433043],\n",
       "       [155.03131611],\n",
       "       [155.84896379],\n",
       "       [152.40347433],\n",
       "       [151.96788865],\n",
       "       [153.11183996],\n",
       "       [156.05010526],\n",
       "       [158.99859474],\n",
       "       [154.54391737],\n",
       "       [173.29071348],\n",
       "       [190.41092555],\n",
       "       [212.0389926 ],\n",
       "       [162.19567815],\n",
       "       [166.73617338],\n",
       "       [163.646167  ],\n",
       "       [182.58605576],\n",
       "       [198.15721551],\n",
       "       [151.58675612],\n",
       "       [156.04851329],\n",
       "       [189.69093165],\n",
       "       [152.8882132 ],\n",
       "       [178.10150677],\n",
       "       [158.19347515],\n",
       "       [163.02615055],\n",
       "       [148.26777359],\n",
       "       [165.17569054],\n",
       "       [171.00501589],\n",
       "       [163.54532929],\n",
       "       [153.3670094 ],\n",
       "       [162.72261896],\n",
       "       [162.58503748],\n",
       "       [155.79958318],\n",
       "       [149.33563682],\n",
       "       [287.34040744],\n",
       "       [228.35578581],\n",
       "       [164.93664841],\n",
       "       [156.52689419],\n",
       "       [170.91144585],\n",
       "       [189.4481222 ],\n",
       "       [432.70367098],\n",
       "       [162.70494912],\n",
       "       [163.1193844 ],\n",
       "       [161.32874874],\n",
       "       [156.74085049],\n",
       "       [173.70662207],\n",
       "       [151.25791128],\n",
       "       [282.0318528 ],\n",
       "       [207.98084336],\n",
       "       [150.89140309],\n",
       "       [151.81915352],\n",
       "       [151.02672021],\n",
       "       [152.27722449],\n",
       "       [163.07000378],\n",
       "       [206.13674334],\n",
       "       [161.35315229],\n",
       "       [160.58777252],\n",
       "       [173.87382796],\n",
       "       [150.47160853],\n",
       "       [166.59259978],\n",
       "       [191.06646955],\n",
       "       [171.24379104],\n",
       "       [167.21774809],\n",
       "       [149.7493305 ],\n",
       "       [166.78720529],\n",
       "       [152.13350257],\n",
       "       [165.87533496],\n",
       "       [153.75141485],\n",
       "       [166.05607751],\n",
       "       [174.58323182],\n",
       "       [187.79131058],\n",
       "       [158.61552417],\n",
       "       [150.54039926],\n",
       "       [179.80997325],\n",
       "       [179.89911346],\n",
       "       [189.98411052],\n",
       "       [151.78288438],\n",
       "       [157.98244569],\n",
       "       [175.58650671],\n",
       "       [163.74053796],\n",
       "       [153.05904799],\n",
       "       [167.69866032],\n",
       "       [157.75911557],\n",
       "       [179.7453058 ],\n",
       "       [157.94783773],\n",
       "       [151.54440587],\n",
       "       [166.01872069],\n",
       "       [158.04770641],\n",
       "       [163.93995892],\n",
       "       [152.68741782],\n",
       "       [160.4448812 ],\n",
       "       [177.00266447],\n",
       "       [155.43199719],\n",
       "       [160.83471515],\n",
       "       [162.18096482],\n",
       "       [149.93145736],\n",
       "       [184.57661666],\n",
       "       [164.86215231],\n",
       "       [148.16603607],\n",
       "       [163.48796907],\n",
       "       [197.41209623],\n",
       "       [152.43463138],\n",
       "       [164.39659613],\n",
       "       [161.62988743],\n",
       "       [176.34085149],\n",
       "       [156.64024021],\n",
       "       [159.29743943],\n",
       "       [160.77616837],\n",
       "       [160.5951193 ],\n",
       "       [210.08198164],\n",
       "       [152.39331937],\n",
       "       [168.34478105],\n",
       "       [156.1460583 ],\n",
       "       [168.38946487],\n",
       "       [158.4120788 ],\n",
       "       [164.10073762],\n",
       "       [164.46424975],\n",
       "       [151.45393077],\n",
       "       [162.20299526],\n",
       "       [145.30092211]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction ----Test dataset\n",
    "Y_pred=LR_model.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5615fbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7990974847548848"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evluation \n",
    "# performance measure\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y_test, Y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "468a0197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total traded quantity-->\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SHAURY~1\\AppData\\Local\\Temp/ipykernel_9988/1154294848.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclose_price\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'total traded quantity-->'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'clsoe price-->'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLR_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclose_price\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "close_price=float(input('total traded quantity-->'))\n",
    "print('clsoe price-->', LR_model.predict([[close_price]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b28095bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING MLR TO PREDICT CLOSING PRICE USING DIFFERENT COMBINATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5ec66f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2]].values\n",
    "Y=data.iloc[:, 5:6].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "88866aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e3984e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1a715689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[177.20356862],\n",
       "       [156.25025793],\n",
       "       [162.52609518],\n",
       "       [153.66332276],\n",
       "       [165.53899502],\n",
       "       [163.34041061],\n",
       "       [167.38487488],\n",
       "       [151.35646486],\n",
       "       [154.29645068],\n",
       "       [200.28083908],\n",
       "       [259.68403905],\n",
       "       [160.50786768],\n",
       "       [157.4065099 ],\n",
       "       [161.8922751 ],\n",
       "       [174.41851771],\n",
       "       [174.30396536],\n",
       "       [162.53123694],\n",
       "       [190.57546169],\n",
       "       [192.24837096],\n",
       "       [166.65198704],\n",
       "       [162.05094766],\n",
       "       [155.43720816],\n",
       "       [150.12755596],\n",
       "       [162.22335463],\n",
       "       [185.20817239],\n",
       "       [153.21537709],\n",
       "       [155.26154804],\n",
       "       [156.98029803],\n",
       "       [149.81153584],\n",
       "       [155.45156552],\n",
       "       [168.20926617],\n",
       "       [159.99606539],\n",
       "       [236.66115253],\n",
       "       [178.22475066],\n",
       "       [162.75208517],\n",
       "       [160.36287022],\n",
       "       [171.11954846],\n",
       "       [174.92903457],\n",
       "       [156.76564957],\n",
       "       [154.87466071],\n",
       "       [155.11589797],\n",
       "       [163.77975373],\n",
       "       [185.82235493],\n",
       "       [162.8386644 ],\n",
       "       [150.45283123],\n",
       "       [158.28322842],\n",
       "       [158.87172196],\n",
       "       [188.67967715],\n",
       "       [174.66844651],\n",
       "       [152.63025535],\n",
       "       [163.47868425],\n",
       "       [168.48094855],\n",
       "       [168.16324747],\n",
       "       [154.79271894],\n",
       "       [162.04980065],\n",
       "       [152.74196985],\n",
       "       [183.74813175],\n",
       "       [150.95487409],\n",
       "       [156.86006997],\n",
       "       [149.04248762],\n",
       "       [163.49548394],\n",
       "       [177.79611624],\n",
       "       [169.60960314],\n",
       "       [153.22575948],\n",
       "       [160.60523471],\n",
       "       [166.52020981],\n",
       "       [173.69982902],\n",
       "       [207.12793511],\n",
       "       [160.35080687],\n",
       "       [162.37415635],\n",
       "       [175.86834406],\n",
       "       [192.70573988],\n",
       "       [155.22709829],\n",
       "       [151.47306403],\n",
       "       [157.74375953],\n",
       "       [220.46091894],\n",
       "       [154.85771269],\n",
       "       [187.51365585],\n",
       "       [212.6886829 ],\n",
       "       [167.20478494],\n",
       "       [176.53654468],\n",
       "       [170.7988711 ],\n",
       "       [198.19013262],\n",
       "       [268.36762135],\n",
       "       [198.68773577],\n",
       "       [167.32306506],\n",
       "       [166.71230377],\n",
       "       [155.84633359],\n",
       "       [155.39074451],\n",
       "       [160.65304314],\n",
       "       [202.52876456],\n",
       "       [149.95870866],\n",
       "       [169.97433149],\n",
       "       [159.29608477],\n",
       "       [163.60509229],\n",
       "       [162.02159022],\n",
       "       [164.86565265],\n",
       "       [176.84467418],\n",
       "       [176.16059345],\n",
       "       [159.13339769],\n",
       "       [157.6443358 ],\n",
       "       [161.739654  ],\n",
       "       [160.57888322],\n",
       "       [159.30579478],\n",
       "       [151.86107859],\n",
       "       [174.72998935],\n",
       "       [171.67543141],\n",
       "       [159.35224855],\n",
       "       [162.42797667],\n",
       "       [189.78297894],\n",
       "       [151.56408296],\n",
       "       [163.69953247],\n",
       "       [157.34708308],\n",
       "       [172.94855941],\n",
       "       [162.65311629],\n",
       "       [186.55524277],\n",
       "       [150.81366372],\n",
       "       [178.53268241],\n",
       "       [156.88732127],\n",
       "       [202.02690957],\n",
       "       [180.78600673],\n",
       "       [167.29376695],\n",
       "       [173.13296051],\n",
       "       [171.47082915],\n",
       "       [151.44277712],\n",
       "       [167.08856152],\n",
       "       [160.40901746],\n",
       "       [155.7233369 ],\n",
       "       [148.48433043],\n",
       "       [155.03131611],\n",
       "       [155.84896379],\n",
       "       [152.40347433],\n",
       "       [151.96788865],\n",
       "       [153.11183996],\n",
       "       [156.05010526],\n",
       "       [158.99859474],\n",
       "       [154.54391737],\n",
       "       [173.29071348],\n",
       "       [190.41092555],\n",
       "       [212.0389926 ],\n",
       "       [162.19567815],\n",
       "       [166.73617338],\n",
       "       [163.646167  ],\n",
       "       [182.58605576],\n",
       "       [198.15721551],\n",
       "       [151.58675612],\n",
       "       [156.04851329],\n",
       "       [189.69093165],\n",
       "       [152.8882132 ],\n",
       "       [178.10150677],\n",
       "       [158.19347515],\n",
       "       [163.02615055],\n",
       "       [148.26777359],\n",
       "       [165.17569054],\n",
       "       [171.00501589],\n",
       "       [163.54532929],\n",
       "       [153.3670094 ],\n",
       "       [162.72261896],\n",
       "       [162.58503748],\n",
       "       [155.79958318],\n",
       "       [149.33563682],\n",
       "       [287.34040744],\n",
       "       [228.35578581],\n",
       "       [164.93664841],\n",
       "       [156.52689419],\n",
       "       [170.91144585],\n",
       "       [189.4481222 ],\n",
       "       [432.70367098],\n",
       "       [162.70494912],\n",
       "       [163.1193844 ],\n",
       "       [161.32874874],\n",
       "       [156.74085049],\n",
       "       [173.70662207],\n",
       "       [151.25791128],\n",
       "       [282.0318528 ],\n",
       "       [207.98084336],\n",
       "       [150.89140309],\n",
       "       [151.81915352],\n",
       "       [151.02672021],\n",
       "       [152.27722449],\n",
       "       [163.07000378],\n",
       "       [206.13674334],\n",
       "       [161.35315229],\n",
       "       [160.58777252],\n",
       "       [173.87382796],\n",
       "       [150.47160853],\n",
       "       [166.59259978],\n",
       "       [191.06646955],\n",
       "       [171.24379104],\n",
       "       [167.21774809],\n",
       "       [149.7493305 ],\n",
       "       [166.78720529],\n",
       "       [152.13350257],\n",
       "       [165.87533496],\n",
       "       [153.75141485],\n",
       "       [166.05607751],\n",
       "       [174.58323182],\n",
       "       [187.79131058],\n",
       "       [158.61552417],\n",
       "       [150.54039926],\n",
       "       [179.80997325],\n",
       "       [179.89911346],\n",
       "       [189.98411052],\n",
       "       [151.78288438],\n",
       "       [157.98244569],\n",
       "       [175.58650671],\n",
       "       [163.74053796],\n",
       "       [153.05904799],\n",
       "       [167.69866032],\n",
       "       [157.75911557],\n",
       "       [179.7453058 ],\n",
       "       [157.94783773],\n",
       "       [151.54440587],\n",
       "       [166.01872069],\n",
       "       [158.04770641],\n",
       "       [163.93995892],\n",
       "       [152.68741782],\n",
       "       [160.4448812 ],\n",
       "       [177.00266447],\n",
       "       [155.43199719],\n",
       "       [160.83471515],\n",
       "       [162.18096482],\n",
       "       [149.93145736],\n",
       "       [184.57661666],\n",
       "       [164.86215231],\n",
       "       [148.16603607],\n",
       "       [163.48796907],\n",
       "       [197.41209623],\n",
       "       [152.43463138],\n",
       "       [164.39659613],\n",
       "       [161.62988743],\n",
       "       [176.34085149],\n",
       "       [156.64024021],\n",
       "       [159.29743943],\n",
       "       [160.77616837],\n",
       "       [160.5951193 ],\n",
       "       [210.08198164],\n",
       "       [152.39331937],\n",
       "       [168.34478105],\n",
       "       [156.1460583 ],\n",
       "       [168.38946487],\n",
       "       [158.4120788 ],\n",
       "       [164.10073762],\n",
       "       [164.46424975],\n",
       "       [151.45393077],\n",
       "       [162.20299526],\n",
       "       [145.30092211]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction ----Test dataset\n",
    "Y_pred=LR_model.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "caee704c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 0.7990974847548848\n",
      "MSE is---> 2306.751251233312\n",
      "MAE is---> 34.2427067260846\n",
      "RMSE is---> 48.02865031659032\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9e171b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7990974847548848"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evluation \n",
    "# performance measure\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y_test, Y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "711ea515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting close prices with opening abd low price\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "691cd951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,3]].values\n",
    "Y=data.iloc[:, 5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ffc5be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5ddfcf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "8c5c962e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[153.09870064],\n",
       "       [222.2933021 ],\n",
       "       [154.05149167],\n",
       "       [133.96999142],\n",
       "       [316.98711173],\n",
       "       [123.44083762],\n",
       "       [161.40806281],\n",
       "       [127.87396439],\n",
       "       [142.89485976],\n",
       "       [156.00205183],\n",
       "       [168.58677731],\n",
       "       [119.54853343],\n",
       "       [119.91708725],\n",
       "       [158.35559059],\n",
       "       [233.67880537],\n",
       "       [118.92525344],\n",
       "       [244.5055788 ],\n",
       "       [304.21859428],\n",
       "       [154.92102912],\n",
       "       [160.08199868],\n",
       "       [257.75831621],\n",
       "       [139.01591727],\n",
       "       [143.64498167],\n",
       "       [143.32980221],\n",
       "       [176.0384727 ],\n",
       "       [124.87451909],\n",
       "       [154.03934601],\n",
       "       [132.80807478],\n",
       "       [119.26174214],\n",
       "       [108.2267117 ],\n",
       "       [141.38011065],\n",
       "       [153.05327381],\n",
       "       [103.90435806],\n",
       "       [246.38443743],\n",
       "       [155.50124192],\n",
       "       [146.54003788],\n",
       "       [134.25730387],\n",
       "       [275.07167462],\n",
       "       [124.54615164],\n",
       "       [133.29115115],\n",
       "       [152.46563464],\n",
       "       [123.02126908],\n",
       "       [232.41923113],\n",
       "       [144.22921887],\n",
       "       [122.39798909],\n",
       "       [153.80287456],\n",
       "       [149.55031152],\n",
       "       [168.50893792],\n",
       "       [277.45273294],\n",
       "       [120.09529133],\n",
       "       [238.95832187],\n",
       "       [136.32911807],\n",
       "       [159.06483123],\n",
       "       [120.41571124],\n",
       "       [159.77171223],\n",
       "       [135.71631898],\n",
       "       [155.35107856],\n",
       "       [156.9217354 ],\n",
       "       [140.12681919],\n",
       "       [126.06683609],\n",
       "       [138.77656501],\n",
       "       [117.50240032],\n",
       "       [273.6633268 ],\n",
       "       [144.36706285],\n",
       "       [141.91892102],\n",
       "       [138.41543756],\n",
       "       [155.73483257],\n",
       "       [226.47527839],\n",
       "       [154.99248448],\n",
       "       [147.33846742],\n",
       "       [162.56054088],\n",
       "       [139.99980355],\n",
       "       [140.12175246],\n",
       "       [119.47253251],\n",
       "       [119.64278906],\n",
       "       [238.31512242],\n",
       "       [106.2795535 ],\n",
       "       [167.79428311],\n",
       "       [148.11357553],\n",
       "       [154.07953239],\n",
       "       [151.48629393],\n",
       "       [312.07038744],\n",
       "       [170.93035634],\n",
       "       [169.27155292],\n",
       "       [104.05601246],\n",
       "       [147.35908178],\n",
       "       [169.12138956],\n",
       "       [135.83084152],\n",
       "       [157.61036169],\n",
       "       [155.8137143 ],\n",
       "       [279.38722432],\n",
       "       [118.65925023],\n",
       "       [267.54477447],\n",
       "       [152.18897681],\n",
       "       [116.50785942],\n",
       "       [155.68669865],\n",
       "       [171.5235834 ],\n",
       "       [307.15182467],\n",
       "       [155.44769384],\n",
       "       [159.82779368],\n",
       "       [158.23093459],\n",
       "       [120.60894179],\n",
       "       [156.73881204],\n",
       "       [273.21047708],\n",
       "       [119.52084015],\n",
       "       [155.3993862 ],\n",
       "       [126.25482619],\n",
       "       [155.21104866],\n",
       "       [294.08481898],\n",
       "       [277.10496719],\n",
       "       [134.45796079],\n",
       "       [207.97387356],\n",
       "       [121.79601834],\n",
       "       [251.0588274 ],\n",
       "       [161.19508652],\n",
       "       [289.38298192],\n",
       "       [125.01149446],\n",
       "       [152.56478328],\n",
       "       [133.22476252],\n",
       "       [207.81611011],\n",
       "       [161.8788198 ],\n",
       "       [235.37987982],\n",
       "       [157.7149245 ],\n",
       "       [144.28564776],\n",
       "       [128.19185093],\n",
       "       [137.07129244],\n",
       "       [210.65577975],\n",
       "       [148.29632517],\n",
       "       [126.67675437],\n",
       "       [121.67878871],\n",
       "       [149.47125607],\n",
       "       [151.84034246],\n",
       "       [137.78035936],\n",
       "       [128.23002511],\n",
       "       [153.54377655],\n",
       "       [153.39378691],\n",
       "       [129.27488584],\n",
       "       [147.0486216 ],\n",
       "       [208.76636776],\n",
       "       [291.48869971],\n",
       "       [147.90007807],\n",
       "       [151.44662872],\n",
       "       [151.97461074],\n",
       "       [266.8962333 ],\n",
       "       [170.23753193],\n",
       "       [123.65669472],\n",
       "       [152.64654581],\n",
       "       [127.78442804],\n",
       "       [129.27165759],\n",
       "       [196.01374538],\n",
       "       [103.7827566 ],\n",
       "       [159.73860478],\n",
       "       [117.79460578],\n",
       "       [148.31728697],\n",
       "       [160.36660405],\n",
       "       [152.18102927],\n",
       "       [153.73159292],\n",
       "       [131.95425867],\n",
       "       [153.61252482],\n",
       "       [155.95103711],\n",
       "       [125.380222  ],\n",
       "       [197.31027775],\n",
       "       [137.53847373],\n",
       "       [144.85756558],\n",
       "       [143.14889104],\n",
       "       [154.01401237],\n",
       "       [158.96349667],\n",
       "       [184.0152693 ],\n",
       "       [238.36447238],\n",
       "       [116.88488194],\n",
       "       [143.34246903],\n",
       "       [153.46000182],\n",
       "       [145.02004832],\n",
       "       [144.04410958],\n",
       "       [225.78089049],\n",
       "       [282.84878418],\n",
       "       [120.2886956 ],\n",
       "       [124.28198691],\n",
       "       [133.5429965 ],\n",
       "       [150.58451763],\n",
       "       [120.94202851],\n",
       "       [166.35300155],\n",
       "       [155.20310113],\n",
       "       [138.66964256],\n",
       "       [157.16615439],\n",
       "       [118.4557125 ],\n",
       "       [245.48693171],\n",
       "       [136.70808033],\n",
       "       [159.14336551],\n",
       "       [142.36888993],\n",
       "       [150.7145878 ],\n",
       "       [140.55128074],\n",
       "       [154.98200358],\n",
       "       [141.9695883 ],\n",
       "       [146.03197532],\n",
       "       [143.22253232],\n",
       "       [166.14623558],\n",
       "       [245.07007025],\n",
       "       [137.94065617],\n",
       "       [124.86927864],\n",
       "       [146.85067177],\n",
       "       [158.61704824],\n",
       "       [152.95159181],\n",
       "       [145.34806832],\n",
       "       [271.7326861 ],\n",
       "       [157.44027886],\n",
       "       [234.38603381],\n",
       "       [129.09668176],\n",
       "       [120.33193651],\n",
       "       [147.71479506],\n",
       "       [229.59937969],\n",
       "       [116.64046295],\n",
       "       [138.61678936],\n",
       "       [115.9972635 ],\n",
       "       [118.60264761],\n",
       "       [118.2753225 ],\n",
       "       [148.66810724],\n",
       "       [132.84642268],\n",
       "       [199.86849782],\n",
       "       [132.66603268],\n",
       "       [134.18348888],\n",
       "       [157.84482094],\n",
       "       [136.72300553],\n",
       "       [152.63099819],\n",
       "       [263.88665455],\n",
       "       [125.48714445],\n",
       "       [162.76338371],\n",
       "       [231.55309565],\n",
       "       [133.63402389],\n",
       "       [279.29147765],\n",
       "       [154.88032158],\n",
       "       [175.52700816],\n",
       "       [132.30455778],\n",
       "       [155.15042165],\n",
       "       [242.71075434],\n",
       "       [142.84165912],\n",
       "       [266.62158767],\n",
       "       [133.04926552],\n",
       "       [285.39371501],\n",
       "       [128.98993303],\n",
       "       [148.67737209],\n",
       "       [162.90830662],\n",
       "       [136.35139718],\n",
       "       [132.5790297 ],\n",
       "       [150.03828089],\n",
       "       [151.15862138],\n",
       "       [145.06852968]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction ----Test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1c1bca13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.80164107588364"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evluation \n",
    "# performance measure\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y_test, Y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f9aa3fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 99.80164107588364\n",
      "MSE is---> 4.612505378450516\n",
      "MAE is---> 1.4016534254608957\n",
      "RMSE is---> 2.147674411648683\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e712d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting close prices with opening and last price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,4]].values\n",
    "Y=data.iloc[:, 5:6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "19b5f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b0bcf1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ff3690c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[155.32085192],\n",
       "       [173.48572873],\n",
       "       [155.1625673 ],\n",
       "       [134.83952887],\n",
       "       [322.05941356],\n",
       "       [123.87560635],\n",
       "       [163.77513699],\n",
       "       [129.32319348],\n",
       "       [142.99147503],\n",
       "       [165.27711802],\n",
       "       [176.46092205],\n",
       "       [119.74176397],\n",
       "       [121.41462398],\n",
       "       [159.5632815 ],\n",
       "       [236.86710937],\n",
       "       [121.3889429 ],\n",
       "       [247.1624988 ],\n",
       "       [307.21366774],\n",
       "       [155.40410549],\n",
       "       [161.33799723],\n",
       "       [259.69062167],\n",
       "       [140.46514636],\n",
       "       [144.70774967],\n",
       "       [144.19933966],\n",
       "       [177.39108651],\n",
       "       [128.15943836],\n",
       "       [154.81226819],\n",
       "       [133.87084278],\n",
       "       [119.31004977],\n",
       "       [110.15901716],\n",
       "       [143.50564665],\n",
       "       [155.61357854],\n",
       "       [108.44527589],\n",
       "       [248.12351234],\n",
       "       [155.64616483],\n",
       "       [147.98926697],\n",
       "       [137.54222315],\n",
       "       [282.36612772],\n",
       "       [125.60891965],\n",
       "       [134.54714969],\n",
       "       [154.01147901],\n",
       "       [123.93911417],\n",
       "       [236.18722677],\n",
       "       [146.4030625 ],\n",
       "       [122.83275782],\n",
       "       [153.85118219],\n",
       "       [149.84015734],\n",
       "       [171.06924265],\n",
       "       [282.28349658],\n",
       "       [120.81990588],\n",
       "       [241.08385787],\n",
       "       [140.53188243],\n",
       "       [162.54298105],\n",
       "       [121.23694106],\n",
       "       [160.54463441],\n",
       "       [138.80800771],\n",
       "       [157.09015347],\n",
       "       [157.4531194 ],\n",
       "       [141.96250937],\n",
       "       [126.79145064],\n",
       "       [139.11471847],\n",
       "       [118.85501414],\n",
       "       [279.75008898],\n",
       "       [145.18829267],\n",
       "       [144.96230211],\n",
       "       [138.89851392],\n",
       "       [158.87482894],\n",
       "       [236.81311258],\n",
       "       [156.82817466],\n",
       "       [149.0292347 ],\n",
       "       [163.23684779],\n",
       "       [145.65179701],\n",
       "       [140.21836773],\n",
       "       [120.14883942],\n",
       "       [119.8360196 ],\n",
       "       [239.90927442],\n",
       "       [107.05247569],\n",
       "       [169.2435122 ],\n",
       "       [148.93480534],\n",
       "       [155.67368439],\n",
       "       [156.84844157],\n",
       "       [316.94945872],\n",
       "       [171.79989379],\n",
       "       [171.39708892],\n",
       "       [108.50031501],\n",
       "       [148.51846505],\n",
       "       [171.05369502],\n",
       "       [138.77760734],\n",
       "       [159.30112896],\n",
       "       [157.89094266],\n",
       "       [295.32874433],\n",
       "       [120.3500175 ],\n",
       "       [273.34169084],\n",
       "       [153.87974408],\n",
       "       [117.37739688],\n",
       "       [158.68177211],\n",
       "       [173.93896522],\n",
       "       [310.19520577],\n",
       "       [157.71815275],\n",
       "       [162.09825259],\n",
       "       [161.41923859],\n",
       "       [120.94709524],\n",
       "       [159.00927095],\n",
       "       [278.76585527],\n",
       "       [120.05222415],\n",
       "       [156.12400075],\n",
       "       [128.47697746],\n",
       "       [155.98397084],\n",
       "       [297.5629688 ],\n",
       "       [280.72803992],\n",
       "       [135.27919061],\n",
       "       [209.7612561 ],\n",
       "       [123.14863216],\n",
       "       [258.4982034 ],\n",
       "       [161.9680087 ],\n",
       "       [292.2814401 ],\n",
       "       [125.73610901],\n",
       "       [152.90293673],\n",
       "       [134.28753052],\n",
       "       [208.39580174],\n",
       "       [163.37635653],\n",
       "       [239.48602892],\n",
       "       [158.63276959],\n",
       "       [145.49333867],\n",
       "       [129.20631129],\n",
       "       [141.56390262],\n",
       "       [211.23547139],\n",
       "       [148.77940154],\n",
       "       [126.72506201],\n",
       "       [122.78986435],\n",
       "       [150.05094771],\n",
       "       [154.06249373],\n",
       "       [138.16682045],\n",
       "       [129.19617784],\n",
       "       [156.10408128],\n",
       "       [153.49040218],\n",
       "       [130.04780802],\n",
       "       [147.53169797],\n",
       "       [210.60205795],\n",
       "       [292.26162189],\n",
       "       [149.25269189],\n",
       "       [155.79431599],\n",
       "       [153.42383984],\n",
       "       [274.81868567],\n",
       "       [172.94275957],\n",
       "       [124.9610009 ],\n",
       "       [153.80592909],\n",
       "       [128.17088913],\n",
       "       [129.27165759],\n",
       "       [199.73343338],\n",
       "       [106.19813842],\n",
       "       [161.47767969],\n",
       "       [118.85737378],\n",
       "       [150.82928406],\n",
       "       [163.7481386 ],\n",
       "       [154.88625691],\n",
       "       [154.64943802],\n",
       "       [135.38410086],\n",
       "       [155.06175391],\n",
       "       [156.67565166],\n",
       "       [126.05652891],\n",
       "       [208.80749521],\n",
       "       [139.80893264],\n",
       "       [147.75602377],\n",
       "       [143.82519795],\n",
       "       [155.46324146],\n",
       "       [159.30165013],\n",
       "       [196.0921784 ],\n",
       "       [240.68323893],\n",
       "       [119.92826303],\n",
       "       [147.93169449],\n",
       "       [156.50338291],\n",
       "       [145.98620105],\n",
       "       [144.23734012],\n",
       "       [229.64550141],\n",
       "       [283.57339873],\n",
       "       [121.10992542],\n",
       "       [124.52352509],\n",
       "       [136.53806996],\n",
       "       [151.06759399],\n",
       "       [122.82602633],\n",
       "       [171.03884228],\n",
       "       [158.10155931],\n",
       "       [139.05610365],\n",
       "       [159.38830567],\n",
       "       [119.03540414],\n",
       "       [249.73800372],\n",
       "       [139.65484615],\n",
       "       [163.20120697],\n",
       "       [144.83257939],\n",
       "       [152.8401238 ],\n",
       "       [142.77343201],\n",
       "       [157.3973854 ],\n",
       "       [143.70866321],\n",
       "       [146.56335932],\n",
       "       [143.4640705 ],\n",
       "       [167.35392649],\n",
       "       [250.48052553],\n",
       "       [141.17726781],\n",
       "       [125.98035427],\n",
       "       [149.9423605 ],\n",
       "       [160.50104606],\n",
       "       [159.23158455],\n",
       "       [145.73452941],\n",
       "       [274.19637556],\n",
       "       [161.49812032],\n",
       "       [239.941412  ],\n",
       "       [129.91791158],\n",
       "       [127.19162088],\n",
       "       [148.05294851],\n",
       "       [231.19353169],\n",
       "       [118.13799968],\n",
       "       [139.92109554],\n",
       "       [116.67357041],\n",
       "       [122.1774127 ],\n",
       "       [121.02885777],\n",
       "       [148.66810724],\n",
       "       [134.82703578],\n",
       "       [201.65588037],\n",
       "       [135.75772141],\n",
       "       [134.66656524],\n",
       "       [158.66605076],\n",
       "       [137.44762008],\n",
       "       [153.40392037],\n",
       "       [268.18603419],\n",
       "       [126.26006664],\n",
       "       [164.55076626],\n",
       "       [237.15678147],\n",
       "       [135.5180217 ],\n",
       "       [282.91455038],\n",
       "       [155.26678267],\n",
       "       [176.39654562],\n",
       "       [132.93255706],\n",
       "       [158.33872565],\n",
       "       [244.35321397],\n",
       "       [143.51796603],\n",
       "       [283.43264513],\n",
       "       [134.8849557 ],\n",
       "       [285.97340664],\n",
       "       [131.40531485],\n",
       "       [151.96229137],\n",
       "       [162.90830662],\n",
       "       [136.78616591],\n",
       "       [133.25533661],\n",
       "       [150.90781834],\n",
       "       [151.88323592],\n",
       "       [145.55160604]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "Y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5a05caf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 99.33915010927278\n",
      "MSE is---> 15.366960114885535\n",
      "MAE is---> 2.355843110358982\n",
      "RMSE is---> 3.92007144257417\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6f4c4e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 99.33915010927278\n",
      "MSE is---> 15.366960114885535\n",
      "MAE is---> 2.355843110358982\n",
      "RMSE is---> 3.92007144257417\n"
     ]
    }
   ],
   "source": [
    "# predicting close prices with opening and last price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,5]].values\n",
    "Y=data.iloc[:, 5:6].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ffcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9178082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e6e18ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[153.45],\n",
       "       [222.95],\n",
       "       [152.95],\n",
       "       [132.6 ],\n",
       "       [317.6 ],\n",
       "       [122.4 ],\n",
       "       [160.35],\n",
       "       [128.  ],\n",
       "       [141.2 ],\n",
       "       [162.2 ],\n",
       "       [174.85],\n",
       "       [118.25],\n",
       "       [120.45],\n",
       "       [157.1 ],\n",
       "       [233.75],\n",
       "       [118.65],\n",
       "       [242.2 ],\n",
       "       [302.75],\n",
       "       [153.35],\n",
       "       [158.8 ],\n",
       "       [255.25],\n",
       "       [138.65],\n",
       "       [142.7 ],\n",
       "       [142.55],\n",
       "       [175.15],\n",
       "       [126.5 ],\n",
       "       [153.1 ],\n",
       "       [132.15],\n",
       "       [118.05],\n",
       "       [109.1 ],\n",
       "       [142.15],\n",
       "       [153.9 ],\n",
       "       [106.2 ],\n",
       "       [243.25],\n",
       "       [153.8 ],\n",
       "       [145.95],\n",
       "       [135.7 ],\n",
       "       [278.25],\n",
       "       [123.9 ],\n",
       "       [132.6 ],\n",
       "       [152.05],\n",
       "       [121.95],\n",
       "       [233.1 ],\n",
       "       [144.8 ],\n",
       "       [121.25],\n",
       "       [152.1 ],\n",
       "       [147.95],\n",
       "       [169.5 ],\n",
       "       [278.2 ],\n",
       "       [119.3 ],\n",
       "       [237.6 ],\n",
       "       [139.4 ],\n",
       "       [161.15],\n",
       "       [119.95],\n",
       "       [158.75],\n",
       "       [137.55],\n",
       "       [155.6 ],\n",
       "       [155.15],\n",
       "       [140.2 ],\n",
       "       [125.2 ],\n",
       "       [137.5 ],\n",
       "       [117.3 ],\n",
       "       [276.05],\n",
       "       [143.15],\n",
       "       [143.35],\n",
       "       [137.35],\n",
       "       [157.25],\n",
       "       [233.95],\n",
       "       [154.95],\n",
       "       [147.3 ],\n",
       "       [161.25],\n",
       "       [143.6 ],\n",
       "       [138.9 ],\n",
       "       [118.85],\n",
       "       [118.6 ],\n",
       "       [236.15],\n",
       "       [106.  ],\n",
       "       [167.3 ],\n",
       "       [146.9 ],\n",
       "       [152.9 ],\n",
       "       [155.45],\n",
       "       [312.25],\n",
       "       [169.2 ],\n",
       "       [169.5 ],\n",
       "       [105.25],\n",
       "       [146.4 ],\n",
       "       [169.15],\n",
       "       [136.55],\n",
       "       [158.05],\n",
       "       [155.5 ],\n",
       "       [290.85],\n",
       "       [118.95],\n",
       "       [267.95],\n",
       "       [152.15],\n",
       "       [115.65],\n",
       "       [156.35],\n",
       "       [171.15],\n",
       "       [305.55],\n",
       "       [155.55],\n",
       "       [160.25],\n",
       "       [159.3 ],\n",
       "       [119.5 ],\n",
       "       [156.95],\n",
       "       [275.35],\n",
       "       [118.35],\n",
       "       [154.7 ],\n",
       "       [127.25],\n",
       "       [153.5 ],\n",
       "       [292.75],\n",
       "       [277.8 ],\n",
       "       [133.65],\n",
       "       [206.45],\n",
       "       [121.55],\n",
       "       [254.5 ],\n",
       "       [160.05],\n",
       "       [288.45],\n",
       "       [124.3 ],\n",
       "       [151.15],\n",
       "       [132.6 ],\n",
       "       [205.75],\n",
       "       [161.3 ],\n",
       "       [236.1 ],\n",
       "       [156.15],\n",
       "       [143.4 ],\n",
       "       [127.9 ],\n",
       "       [140.2 ],\n",
       "       [208.3 ],\n",
       "       [147.25],\n",
       "       [125.45],\n",
       "       [120.75],\n",
       "       [148.2 ],\n",
       "       [151.45],\n",
       "       [136.6 ],\n",
       "       [127.8 ],\n",
       "       [154.4 ],\n",
       "       [151.6 ],\n",
       "       [128.65],\n",
       "       [145.9 ],\n",
       "       [206.8 ],\n",
       "       [287.8 ],\n",
       "       [147.5 ],\n",
       "       [153.7 ],\n",
       "       [151.15],\n",
       "       [270.7 ],\n",
       "       [171.1 ],\n",
       "       [123.35],\n",
       "       [151.9 ],\n",
       "       [126.85],\n",
       "       [128.  ],\n",
       "       [196.7 ],\n",
       "       [104.55],\n",
       "       [159.35],\n",
       "       [117.  ],\n",
       "       [149.15],\n",
       "       [162.  ],\n",
       "       [152.2 ],\n",
       "       [152.65],\n",
       "       [133.85],\n",
       "       [152.95],\n",
       "       [154.85],\n",
       "       [124.45],\n",
       "       [205.95],\n",
       "       [137.75],\n",
       "       [145.15],\n",
       "       [141.9 ],\n",
       "       [154.05],\n",
       "       [157.45],\n",
       "       [193.85],\n",
       "       [237.55],\n",
       "       [118.85],\n",
       "       [146.35],\n",
       "       [154.45],\n",
       "       [143.65],\n",
       "       [142.75],\n",
       "       [226.8 ],\n",
       "       [280.2 ],\n",
       "       [119.35],\n",
       "       [123.25],\n",
       "       [135.3 ],\n",
       "       [149.45],\n",
       "       [121.4 ],\n",
       "       [168.6 ],\n",
       "       [156.4 ],\n",
       "       [137.1 ],\n",
       "       [157.55],\n",
       "       [117.7 ],\n",
       "       [246.3 ],\n",
       "       [137.  ],\n",
       "       [161.6 ],\n",
       "       [143.35],\n",
       "       [151.1 ],\n",
       "       [141.25],\n",
       "       [154.9 ],\n",
       "       [141.65],\n",
       "       [144.6 ],\n",
       "       [141.95],\n",
       "       [164.45],\n",
       "       [246.9 ],\n",
       "       [139.6 ],\n",
       "       [124.45],\n",
       "       [147.65],\n",
       "       [158.05],\n",
       "       [157.45],\n",
       "       [144.05],\n",
       "       [269.8 ],\n",
       "       [159.8 ],\n",
       "       [237.05],\n",
       "       [128.35],\n",
       "       [124.4 ],\n",
       "       [146.2 ],\n",
       "       [227.8 ],\n",
       "       [117.3 ],\n",
       "       [138.5 ],\n",
       "       [115.1 ],\n",
       "       [120.95],\n",
       "       [119.6 ],\n",
       "       [147.45],\n",
       "       [133.45],\n",
       "       [198.6 ],\n",
       "       [133.8 ],\n",
       "       [133.2 ],\n",
       "       [156.95],\n",
       "       [135.6 ],\n",
       "       [151.25],\n",
       "       [264.5 ],\n",
       "       [124.75],\n",
       "       [162.55],\n",
       "       [234.6 ],\n",
       "       [133.35],\n",
       "       [278.5 ],\n",
       "       [153.85],\n",
       "       [173.75],\n",
       "       [131.15],\n",
       "       [156.05],\n",
       "       [245.15],\n",
       "       [141.6 ],\n",
       "       [281.  ],\n",
       "       [132.95],\n",
       "       [281.95],\n",
       "       [130.1 ],\n",
       "       [149.45],\n",
       "       [161.1 ],\n",
       "       [134.95],\n",
       "       [131.35],\n",
       "       [149.05],\n",
       "       [149.95],\n",
       "       [143.65]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "Y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6fb5bed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 100.0\n",
      "MSE is---> 3.87544686976269e-27\n",
      "MAE is---> 5.948997479967154e-14\n",
      "RMSE is---> 6.225308723077668e-14\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb86811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "fecd22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting close prices with opening and last price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,6]].values\n",
    "Y=data.iloc[:, 5:6].values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3250a27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "2eb6d0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 98.46231965047583\n",
      "MSE is---> 35.75618749755461\n",
      "MAE is---> 2.6775305989710216\n",
      "RMSE is---> 5.979647773703282\n"
     ]
    }
   ],
   "source": [
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b4bbd16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.46231965047583"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evluation \n",
    "# performance measure\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y_test, Y_pred)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7768ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting close prices with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,3,2]].values\n",
    "Y=data.iloc[:, 5:6].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fca3cc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4a1f850d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b5116635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 0.7990974847548848\n",
      "MSE is---> 2306.751251233312\n",
      "MAE is---> 34.2427067260846\n",
      "RMSE is---> 48.02865031659032\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a43ba72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting close prices with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,3,2]].values\n",
    "Y=data.iloc[:, 5:6].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "be225c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[137.8 , 136.15, 138.5 ],\n",
       "       [134.  , 132.25, 134.5 ],\n",
       "       [120.75, 120.75, 122.95],\n",
       "       ...,\n",
       "       [168.  , 167.25, 170.  ],\n",
       "       [134.25, 133.2 , 136.15],\n",
       "       [146.05, 145.5 , 148.8 ]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b4f10c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[152.95      , 151.05      , 154.85      ],\n",
       "       [221.        , 219.1       , 224.5       ],\n",
       "       [156.5       , 151.85      , 157.        ],\n",
       "       [132.95      , 132.3       , 133.9       ],\n",
       "       [314.65      , 312.2       , 319.2       ],\n",
       "       [122.5       , 121.95      , 123.95      ],\n",
       "       [164.4       , 159.05      , 167.9       ],\n",
       "       [128.        , 126.25      , 129.        ],\n",
       "       [143.2       , 141.        , 143.55      ],\n",
       "       [154.        , 154.        , 163.9       ],\n",
       "       [171.65      , 166.1       , 177.15      ],\n",
       "       [121.        , 118.        , 121.15      ],\n",
       "       [121.6       , 118.35      , 122.45      ],\n",
       "       [158.5       , 156.2       , 160.4       ],\n",
       "       [234.05      , 230.2       , 235.95      ],\n",
       "       [123.        , 117.25      , 125.35      ],\n",
       "       [243.7       , 240.9       , 247.        ],\n",
       "       [301.        , 299.7       , 306.35      ],\n",
       "       [156.5       , 152.75      , 157.8       ],\n",
       "       [158.25      , 158.        , 161.65      ],\n",
       "       [265.        , 253.5       , 265.4       ],\n",
       "       [138.15      , 137.25      , 138.9       ],\n",
       "       [142.75      , 141.8       , 143.        ],\n",
       "       [142.25      , 141.5       , 143.35      ],\n",
       "       [173.8       , 173.7       , 177.4       ],\n",
       "       [124.1       , 123.35      , 127.45      ],\n",
       "       [153.4       , 152.        , 154.7       ],\n",
       "       [132.9       , 131.1       , 133.8       ],\n",
       "       [118.2       , 117.85      , 119.45      ],\n",
       "       [107.3       , 107.        , 109.85      ],\n",
       "       [140.        , 139.6       , 144.4       ],\n",
       "       [151.1       , 151.1       , 154.35      ],\n",
       "       [107.8       , 102.5       , 108.05      ],\n",
       "       [257.9       , 242.1       , 257.9       ],\n",
       "       [153.65      , 153.5       , 156.5       ],\n",
       "       [147.45      , 144.55      , 148.75      ],\n",
       "       [132.9       , 132.6       , 136.4       ],\n",
       "       [271.1       , 271.1       , 279.8       ],\n",
       "       [126.2       , 122.9       , 127.        ],\n",
       "       [132.9       , 131.6       , 133.3       ],\n",
       "       [152.85      , 150.4       , 152.85      ],\n",
       "       [122.8       , 121.5       , 124.2       ],\n",
       "       [239.7       , 228.6       , 243.3       ],\n",
       "       [145.7       , 142.25      , 145.7       ],\n",
       "       [124.8       , 120.75      , 125.        ],\n",
       "       [153.5       , 151.75      , 154.5       ],\n",
       "       [147.75      , 147.65      , 150.45      ],\n",
       "       [166.3       , 166.3       , 170.75      ],\n",
       "       [278.05      , 273.2       , 281.3       ],\n",
       "       [120.35      , 118.6       , 121.2       ],\n",
       "       [241.        , 235.3       , 241.55      ],\n",
       "       [134.7       , 134.65      , 141.9       ],\n",
       "       [159.15      , 156.9       , 162.15      ],\n",
       "       [120.        , 118.95      , 122.        ],\n",
       "       [158.8       , 157.65      , 159.9       ],\n",
       "       [135.        , 134.        , 138.9       ],\n",
       "       [154.5       , 153.3       , 157.7       ],\n",
       "       [157.85      , 154.75      , 157.95      ],\n",
       "       [139.1       , 138.35      , 140.95      ],\n",
       "       [124.75      , 124.55      , 125.65      ],\n",
       "       [140.1       , 136.9       , 141.9       ],\n",
       "       [117.8       , 116.05      , 118.8       ],\n",
       "       [270.        , 269.7       , 276.65      ],\n",
       "       [142.7       , 142.55      , 144.8       ],\n",
       "       [141.1       , 140.1       , 144.2       ],\n",
       "       [140.6       , 136.5       , 141.2       ],\n",
       "       [155.4       , 153.65      , 157.65      ],\n",
       "       [223.45      , 223.3       , 236.7       ],\n",
       "       [155.05      , 152.9       , 156.5       ],\n",
       "       [147.        , 145.4       , 148.5       ],\n",
       "       [160.45      , 160.45      , 163.35      ],\n",
       "       [138.5       , 138.25      , 145.8       ],\n",
       "       [139.        , 138.35      , 140.45      ],\n",
       "       [119.5       , 118.        , 119.8       ],\n",
       "       [120.        , 118.15      , 120.25      ],\n",
       "       [240.7       , 234.65      , 244.        ],\n",
       "       [105.1       , 105.1       , 108.45      ],\n",
       "       [167.45      , 165.5       , 169.5       ],\n",
       "       [148.95      , 146.1       , 149.9       ],\n",
       "       [156.1       , 151.9       , 156.8       ],\n",
       "       [155.45      , 149.25      , 161.35      ],\n",
       "       [312.        , 307.25      , 313.5       ],\n",
       "       [175.        , 168.35      , 175.        ],\n",
       "       [167.05      , 167.05      , 172.8       ],\n",
       "       [112.7       , 102.4       , 115.8       ],\n",
       "       [145.5       , 145.5       , 149.7       ],\n",
       "       [167.9       , 166.85      , 170.65      ],\n",
       "       [134.4       , 134.15      , 138.85      ],\n",
       "       [160.        , 155.35      , 160.2       ],\n",
       "       [155.05      , 153.75      , 155.9       ],\n",
       "       [280.        , 275.1       , 293.95      ],\n",
       "       [117.75      , 117.25      , 119.2       ],\n",
       "       [277.        , 263.        , 277.05      ],\n",
       "       [150.25      , 150.25      , 153.6       ],\n",
       "       [120.1       , 114.9       , 121.8       ],\n",
       "       [154.45      , 153.65      , 157.        ],\n",
       "       [170.5       , 169.2       , 172.25      ],\n",
       "       [305.5       , 302.5       , 308.8       ],\n",
       "       [154.5       , 153.4       , 157.4       ],\n",
       "       [158.        , 157.75      , 161.        ],\n",
       "       [158.9       , 156.05      , 160.25      ],\n",
       "       [120.        , 119.15      , 121.        ],\n",
       "       [157.1       , 154.6       , 158.1       ],\n",
       "       [271.55      , 269.15      , 276.85      ],\n",
       "       [119.5       , 118.05      , 120.1       ],\n",
       "       [154.5       , 153.35      , 156.5       ],\n",
       "       [125.6       , 124.7       , 128.65      ],\n",
       "       [155.55      , 153.1       , 156.25      ],\n",
       "       [297.4       , 289.4       , 300.        ],\n",
       "       [275.        , 273.        , 281.65      ],\n",
       "       [134.        , 132.75      , 135.        ],\n",
       "       [207.25      , 205.        , 210.55      ],\n",
       "       [121.5       , 120.3       , 123.4       ],\n",
       "       [251.        , 247.3       , 255.5       ],\n",
       "       [161.15      , 159.        , 163.45      ],\n",
       "       [287.55      , 285.05      , 289.9       ],\n",
       "       [125.85      , 123.4       , 127.        ],\n",
       "       [152.9       , 150.5       , 153.15      ],\n",
       "       [134.45      , 131.45      , 134.6       ],\n",
       "       [207.95      , 204.8       , 209.3       ],\n",
       "       [162.25      , 159.65      , 163.9       ],\n",
       "       [233.3       , 232.        , 236.75      ],\n",
       "       [158.25      , 155.55      , 160.        ],\n",
       "       [143.        , 142.45      , 146.        ],\n",
       "       [127.6       , 126.6       , 128.4       ],\n",
       "       [136.        , 135.35      , 142.8       ],\n",
       "       [209.65      , 207.65      , 211.35      ],\n",
       "       [150.65      , 146.2       , 150.65      ],\n",
       "       [126.3       , 125.1       , 126.8       ],\n",
       "       [123.        , 120.1       , 124.4       ],\n",
       "       [149.05      , 147.5       , 150.35      ],\n",
       "       [151.95      , 149.8       , 152.1       ],\n",
       "       [137.6       , 136.        , 138.7       ],\n",
       "       [127.4       , 126.65      , 129.4       ],\n",
       "       [152.2       , 151.55      , 155.35      ],\n",
       "       [152.1       , 151.4       , 154.2       ],\n",
       "       [128.        , 127.7       , 130.45      ],\n",
       "       [147.        , 145.1       , 148.45      ],\n",
       "       [211.45      , 205.6       , 211.45      ],\n",
       "       [298.6       , 286.65      , 298.6       ],\n",
       "       [148.55      , 145.9       , 149.4       ],\n",
       "       [149.9       , 149.5       , 154.5       ],\n",
       "       [154.6       , 149.8       , 155.        ],\n",
       "       [264.2       , 263.        , 271.9       ],\n",
       "       [168.        , 168.        , 172.95      ],\n",
       "       [123.9       , 122.1       , 125.        ],\n",
       "       [150.7       , 150.7       , 153.        ],\n",
       "       [131.        , 126.        , 132.        ],\n",
       "       [131.75      , 127.5       , 132.6       ],\n",
       "       [194.3       , 193.3       , 197.4       ],\n",
       "       [105.4       , 102.5       , 106.5       ],\n",
       "       [159.1       , 157.6       , 162.4       ],\n",
       "       [118.8       , 116.3       , 118.85      ],\n",
       "       [147.25      , 146.4       , 150.2       ],\n",
       "       [159.1       , 158.25      , 162.9       ],\n",
       "       [152.        , 150.15      , 153.8       ],\n",
       "       [154.        , 151.65      , 154.75      ],\n",
       "       [130.35      , 130.35      , 134.8       ],\n",
       "       [151.65      , 151.65      , 154.5       ],\n",
       "       [154.9       , 153.9       , 156.35      ],\n",
       "       [125.5       , 123.8       , 125.5       ],\n",
       "       [195.1       , 194.6       , 207.2       ],\n",
       "       [139.5       , 135.65      , 141.2       ],\n",
       "       [143.8       , 143.        , 146.        ],\n",
       "       [144.4       , 141.2       , 144.4       ],\n",
       "       [152.9       , 152.        , 156.        ],\n",
       "       [157.15      , 156.9       , 158.95      ],\n",
       "       [182.5       , 181.5       , 196.75      ],\n",
       "       [235.        , 235.        , 238.5       ],\n",
       "       [116.1       , 115.5       , 119.35      ],\n",
       "       [142.5       , 141.5       , 147.4       ],\n",
       "       [151.5       , 151.5       , 154.8       ],\n",
       "       [145.1       , 143.1       , 146.8       ],\n",
       "       [143.        , 142.2       , 144.15      ],\n",
       "       [225.        , 222.5       , 230.25      ],\n",
       "       [287.3       , 278.3       , 290.65      ],\n",
       "       [119.4       , 118.85      , 120.35      ],\n",
       "       [124.8       , 122.7       , 125.3       ],\n",
       "       [132.15      , 131.9       , 135.8       ],\n",
       "       [151.        , 148.55      , 151.        ],\n",
       "       [119.9       , 119.5       , 125.        ],\n",
       "       [165.7       , 164.1       , 172.9       ],\n",
       "       [157.3       , 153.        , 157.8       ],\n",
       "       [140.85      , 136.75      , 142.25      ],\n",
       "       [156.        , 155.1       , 158.45      ],\n",
       "       [118.5       , 117.        , 119.        ],\n",
       "       [244.        , 241.9       , 249.2       ],\n",
       "       [147.9       , 134.35      , 148.        ],\n",
       "       [160.7       , 156.9       , 162.7       ],\n",
       "       [141.4       , 140.55      , 143.9       ],\n",
       "       [148.8       , 148.8       , 151.95      ],\n",
       "       [139.85      , 138.75      , 141.85      ],\n",
       "       [156.75      , 152.8       , 157.        ],\n",
       "       [142.1       , 140.1       , 145.8       ],\n",
       "       [145.05      , 144.15      , 146.4       ],\n",
       "       [144.9       , 141.25      , 146.85      ],\n",
       "       [170.2       , 163.65      , 171.8       ],\n",
       "       [243.4       , 241.5       , 249.65      ],\n",
       "       [136.95      , 136.2       , 140.9       ],\n",
       "       [124.95      , 123.3       , 125.95      ],\n",
       "       [145.        , 145.        , 148.35      ],\n",
       "       [160.8       , 156.35      , 162.85      ],\n",
       "       [151.        , 151.        , 158.2       ],\n",
       "       [144.9       , 143.45      , 145.25      ],\n",
       "       [274.8       , 267.45      , 275.45      ],\n",
       "       [158.55      , 155.25      , 160.9       ],\n",
       "       [231.8       , 231.05      , 239.35      ],\n",
       "       [129.25      , 127.45      , 129.25      ],\n",
       "       [119.3       , 118.9       , 126.5       ],\n",
       "       [146.8       , 145.8       , 147.75      ],\n",
       "       [226.95      , 226.35      , 231.4       ],\n",
       "       [117.95      , 115.15      , 119.8       ],\n",
       "       [137.9       , 136.85      , 139.7       ],\n",
       "       [117.65      , 114.5       , 117.65      ],\n",
       "       [121.4       , 117.        , 122.1       ],\n",
       "       [117.8       , 116.85      , 120.15      ],\n",
       "       [147.5       , 146.75      , 149.45      ],\n",
       "       [131.75      , 131.2       , 134.        ],\n",
       "       [206.5       , 196.65      , 207.        ],\n",
       "       [131.05      , 131.05      , 136.        ],\n",
       "       [133.35      , 132.5       , 135.25      ],\n",
       "       [157.        , 155.75      , 158.3       ],\n",
       "       [135.8       , 135.        , 136.95      ],\n",
       "       [152.3       , 150.6       , 154.5       ],\n",
       "       [260.1       , 260.1       , 266.95      ],\n",
       "       [124.75      , 123.95      , 125.5       ],\n",
       "       [163.5       , 160.5       , 165.        ],\n",
       "       [235.        , 227.95      , 237.        ],\n",
       "       [134.9       , 131.85      , 134.9       ],\n",
       "       [275.25      , 275.25      , 281.25      ],\n",
       "       [156.65      , 152.7       , 157.35      ],\n",
       "       [176.1       , 173.05      , 178.7       ],\n",
       "       [133.45      , 130.55      , 134.55      ],\n",
       "       [153.4       , 153.15      , 156.55      ],\n",
       "       [168.23225675, 243.        , 247.        ],\n",
       "       [142.15      , 141.        , 143.2       ],\n",
       "       [264.5       , 262.7       , 284.5       ],\n",
       "       [134.8       , 131.25      , 135.        ],\n",
       "       [287.95      , 280.9       , 289.        ],\n",
       "       [129.05      , 127.35      , 130.65      ],\n",
       "       [152.45      , 146.5       , 153.5       ],\n",
       "       [163.5       , 160.65      , 164.8       ],\n",
       "       [138.        , 134.5       , 138.        ],\n",
       "       [134.1       , 130.8       , 136.25      ],\n",
       "       [148.8       , 148.1       , 149.6       ],\n",
       "       [153.75      , 149.        , 153.75      ],\n",
       "       [144.15      , 143.2       , 144.15      ]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c6a52352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e60fd691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[153.03994982],\n",
       "       [222.26162273],\n",
       "       [154.0755573 ],\n",
       "       [133.73743879],\n",
       "       [316.9134893 ],\n",
       "       [123.27839793],\n",
       "       [161.81234349],\n",
       "       [127.75682795],\n",
       "       [142.71172423],\n",
       "       [156.66344023],\n",
       "       [169.21616366],\n",
       "       [119.46437366],\n",
       "       [119.93219843],\n",
       "       [158.32040977],\n",
       "       [233.6145942 ],\n",
       "       [119.3292792 ],\n",
       "       [244.48185835],\n",
       "       [304.16138656],\n",
       "       [154.95356544],\n",
       "       [160.03069495],\n",
       "       [258.14488465],\n",
       "       [138.7719114 ],\n",
       "       [143.3394004 ],\n",
       "       [143.10226621],\n",
       "       [175.9613913 ],\n",
       "       [124.93860416],\n",
       "       [153.86769336],\n",
       "       [132.67335224],\n",
       "       [119.06858515],\n",
       "       [108.1984761 ],\n",
       "       [141.49457024],\n",
       "       [152.97869102],\n",
       "       [104.06736301],\n",
       "       [247.12841687],\n",
       "       [155.38979646],\n",
       "       [146.51637716],\n",
       "       [134.27811438],\n",
       "       [275.33829014],\n",
       "       [124.54992704],\n",
       "       [133.05569336],\n",
       "       [152.24438847],\n",
       "       [122.91994922],\n",
       "       [233.18347552],\n",
       "       [144.11372378],\n",
       "       [122.40526651],\n",
       "       [153.62894552],\n",
       "       [149.43076842],\n",
       "       [168.5344746 ],\n",
       "       [277.53107243],\n",
       "       [119.97844614],\n",
       "       [238.8940928 ],\n",
       "       [136.73654429],\n",
       "       [159.14651937],\n",
       "       [120.36515688],\n",
       "       [159.54324747],\n",
       "       [135.8399887 ],\n",
       "       [155.3711335 ],\n",
       "       [156.75890526],\n",
       "       [139.99003145],\n",
       "       [125.8065419 ],\n",
       "       [138.85204379],\n",
       "       [117.40798092],\n",
       "       [273.73047087],\n",
       "       [144.1962721 ],\n",
       "       [141.93969018],\n",
       "       [138.43667463],\n",
       "       [155.69622643],\n",
       "       [227.36947055],\n",
       "       [154.90127371],\n",
       "       [147.2213627 ],\n",
       "       [162.42605887],\n",
       "       [140.42789629],\n",
       "       [139.9315473 ],\n",
       "       [119.2737197 ],\n",
       "       [119.4687199 ],\n",
       "       [238.59002081],\n",
       "       [106.31858448],\n",
       "       [167.72447633],\n",
       "       [148.04300746],\n",
       "       [154.08639551],\n",
       "       [152.2548052 ],\n",
       "       [311.86875583],\n",
       "       [171.03705145],\n",
       "       [169.44055592],\n",
       "       [104.97542299],\n",
       "       [147.40303251],\n",
       "       [169.04788689],\n",
       "       [135.94988136],\n",
       "       [157.59313918],\n",
       "       [155.57916452],\n",
       "       [280.66029873],\n",
       "       [118.50289821],\n",
       "       [268.09010892],\n",
       "       [152.12745146],\n",
       "       [116.79637082],\n",
       "       [155.59836586],\n",
       "       [171.35510323],\n",
       "       [307.00843105],\n",
       "       [155.42527301],\n",
       "       [159.7323893 ],\n",
       "       [158.18286371],\n",
       "       [120.42877845],\n",
       "       [156.62423538],\n",
       "       [273.31208664],\n",
       "       [119.35102907],\n",
       "       [155.28097747],\n",
       "       [126.29555147],\n",
       "       [155.06193968],\n",
       "       [294.33044924],\n",
       "       [277.31368116],\n",
       "       [134.28254795],\n",
       "       [207.98192834],\n",
       "       [121.74443291],\n",
       "       [251.23366518],\n",
       "       [161.18518713],\n",
       "       [289.12859097],\n",
       "       [124.97877178],\n",
       "       [152.36684531],\n",
       "       [133.11064743],\n",
       "       [207.68574504],\n",
       "       [161.83432429],\n",
       "       [235.26132806],\n",
       "       [157.69948468],\n",
       "       [144.25059885],\n",
       "       [127.98590648],\n",
       "       [137.48506204],\n",
       "       [210.45740286],\n",
       "       [148.25963252],\n",
       "       [126.45817753],\n",
       "       [121.72074644],\n",
       "       [149.3227656 ],\n",
       "       [151.6108992 ],\n",
       "       [137.63953251],\n",
       "       [128.13604169],\n",
       "       [153.51396699],\n",
       "       [153.25146563],\n",
       "       [129.18938365],\n",
       "       [146.95288276],\n",
       "       [208.72002135],\n",
       "       [291.7962002 ],\n",
       "       [147.80127113],\n",
       "       [151.56136813],\n",
       "       [152.00521765],\n",
       "       [267.17436489],\n",
       "       [170.31510424],\n",
       "       [123.56434535],\n",
       "       [152.46679246],\n",
       "       [127.95254749],\n",
       "       [129.35398996],\n",
       "       [195.91602957],\n",
       "       [103.83041927],\n",
       "       [159.7865272 ],\n",
       "       [117.65926796],\n",
       "       [148.29413852],\n",
       "       [160.4119608 ],\n",
       "       [152.10873854],\n",
       "       [153.58253553],\n",
       "       [132.05986179],\n",
       "       [153.49205965],\n",
       "       [155.75685951],\n",
       "       [125.15251853],\n",
       "       [198.17065919],\n",
       "       [137.66251192],\n",
       "       [144.75387679],\n",
       "       [143.01383454],\n",
       "       [153.99951834],\n",
       "       [158.73601305],\n",
       "       [185.18866015],\n",
       "       [238.13094168],\n",
       "       [116.94214591],\n",
       "       [143.56107864],\n",
       "       [153.39011034],\n",
       "       [144.96543467],\n",
       "       [143.82497673],\n",
       "       [225.98957491],\n",
       "       [283.29046835],\n",
       "       [120.07733831],\n",
       "       [124.147595  ],\n",
       "       [133.57773257],\n",
       "       [150.36739171],\n",
       "       [121.17940456],\n",
       "       [166.83061744],\n",
       "       [155.19394562],\n",
       "       [138.77963772],\n",
       "       [157.07218782],\n",
       "       [118.28145558],\n",
       "       [245.61178714],\n",
       "       [137.50610135],\n",
       "       [159.24918962],\n",
       "       [142.30853075],\n",
       "       [150.63396312],\n",
       "       [140.46100857],\n",
       "       [154.9147227 ],\n",
       "       [142.14494334],\n",
       "       [145.8395882 ],\n",
       "       [143.34448936],\n",
       "       [166.43326814],\n",
       "       [245.29552238],\n",
       "       [138.04310839],\n",
       "       [124.74995235],\n",
       "       [146.80083902],\n",
       "       [158.78661929],\n",
       "       [153.31822396],\n",
       "       [145.09377646],\n",
       "       [271.7525577 ],\n",
       "       [157.54505319],\n",
       "       [234.67915678],\n",
       "       [128.86960911],\n",
       "       [120.80510042],\n",
       "       [147.48283565],\n",
       "       [229.54373519],\n",
       "       [116.73492477],\n",
       "       [138.5040401 ],\n",
       "       [115.91729221],\n",
       "       [118.70475859],\n",
       "       [118.25976046],\n",
       "       [148.52377571],\n",
       "       [132.75269664],\n",
       "       [200.24830518],\n",
       "       [132.82589859],\n",
       "       [134.07407218],\n",
       "       [157.65167648],\n",
       "       [136.51990824],\n",
       "       [152.58922272],\n",
       "       [263.97122817],\n",
       "       [125.26399985],\n",
       "       [162.73528847],\n",
       "       [231.78537906],\n",
       "       [133.50665138],\n",
       "       [279.24741273],\n",
       "       [154.86350304],\n",
       "       [175.59814999],\n",
       "       [132.2897486 ],\n",
       "       [155.08200874],\n",
       "       [244.3129349 ],\n",
       "       [142.6446944 ],\n",
       "       [268.32616354],\n",
       "       [132.9893579 ],\n",
       "       [285.40200882],\n",
       "       [128.93295289],\n",
       "       [148.88863665],\n",
       "       [162.84440862],\n",
       "       [136.25754257],\n",
       "       [132.71592939],\n",
       "       [149.75817256],\n",
       "       [151.14197259],\n",
       "       [144.73191948]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "Y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5f2f9748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 99.83444586273629\n",
      "MSE is---> 3.849684867748498\n",
      "MAE is---> 1.2968810014276724\n",
      "RMSE is---> 1.9620613822580826\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "bddeef1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 100.0\n",
      "MSE is---> 3.0790997703641967e-27\n",
      "MAE is---> 3.7396986092636855e-14\n",
      "RMSE is---> 5.5489636603281126e-14\n"
     ]
    }
   ],
   "source": [
    "# predicting close prices with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,4,5]].values\n",
    "Y=data.iloc[:, 5:6].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a3c588a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 99.62608277159055\n",
      "MSE is---> 8.694820436322532\n",
      "MAE is---> 1.6680169658744803\n",
      "RMSE is---> 2.948698091755501\n"
     ]
    }
   ],
   "source": [
    "# predicting close prices with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2,6]].values\n",
    "Y=data.iloc[:, 5:6].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "faf60419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 100.0\n",
      "MSE is---> 1.7401247008129388e-25\n",
      "MAE is---> 1.937739217846168e-13\n",
      "RMSE is---> 4.1714801939035246e-13\n"
     ]
    }
   ],
   "source": [
    "# predicting close prices with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2,3,4,5,7]].values\n",
    "Y=data.iloc[:, 5:6].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6d0256bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 100.0\n",
      "MSE is---> 3.841107467119224e-27\n",
      "MAE is---> 5.868450125306091e-14\n",
      "RMSE is---> 6.197666873202547e-14\n"
     ]
    }
   ],
   "source": [
    "# predicting close prices with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2,3,4,5]].values\n",
    "Y=data.iloc[:, 5:6].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ec963e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 99.61551774597132\n",
      "MSE is---> 8.940492455916756\n",
      "MAE is---> 1.7821185170559968\n",
      "RMSE is---> 2.9900656273594994\n"
     ]
    }
   ],
   "source": [
    "# predicting close prices with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2,6,7]].values\n",
    "Y=data.iloc[:, 5:6].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c52a6524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 99.83871591436096\n",
      "MSE is---> 3.7503919512697266\n",
      "MAE is---> 1.3030072669918424\n",
      "RMSE is---> 1.9365928718421244\n"
     ]
    }
   ],
   "source": [
    "# predicting close prices with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [3,6,7]].values\n",
    "Y=data.iloc[:, 5:6].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "bcd3b7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 99.55991744241548\n",
      "MSE is---> 10.233384622665497\n",
      "MAE is---> 0.5281010035749621\n",
      "RMSE is---> 3.198966180294111\n"
     ]
    }
   ],
   "source": [
    "# predicting close prices with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [2,4,7]].values\n",
    "Y=data.iloc[:, 5:6].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "655a58d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 98.49819435463007\n",
      "MSE is---> 34.92198118897091\n",
      "MAE is---> 2.864023242491799\n",
      "RMSE is---> 5.909482311418735\n"
     ]
    }
   ],
   "source": [
    "# predicting close prices with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,6,7]].values\n",
    "Y=data.iloc[:, 5:6].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e6524e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 32.92589856440523\n",
      "MSE is---> 20797088.947809722\n",
      "MAE is---> 2239.483633048485\n",
      "RMSE is---> 4560.382544020811\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2,3,4]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e37b093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 28.87971241009214\n",
      "MSE is---> 22051655.040378936\n",
      "MAE is---> 2291.914189633077\n",
      "RMSE is---> 4695.918977194872\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2,3]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bc5414ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 26.616488275112914\n",
      "MSE is---> 22753393.455603004\n",
      "MAE is---> 2345.009838498867\n",
      "RMSE is---> 4770.051724625531\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b5d2aa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 28.93405828070106\n",
      "MSE is---> 22034804.48434003\n",
      "MAE is---> 2293.1479643666476\n",
      "RMSE is---> 4694.124464086996\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [2,3]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e87dbd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 32.935335181791956\n",
      "MSE is---> 20794163.0171307\n",
      "MAE is---> 2242.732098079837\n",
      "RMSE is---> 4560.061733916626\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [3,4,2]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "943e930b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 96.45281378573219\n",
      "MSE is---> 1099845.4788605382\n",
      "MAE is---> 725.3022795791046\n",
      "RMSE is---> 1048.7351805201056\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [5,6]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "55ee7a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 96.45116086948047\n",
      "MSE is---> 1100357.9843667566\n",
      "MAE is---> 724.8777794290964\n",
      "RMSE is---> 1048.979496637926\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [3,4,5,6]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "dc2cc16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0541e7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 24.542753305598485\n",
      "MSE is---> 23396378.597291213\n",
      "MAE is---> 2388.2390315112675\n",
      "RMSE is---> 4836.980318059111\n"
     ]
    }
   ],
   "source": [
    "# Extraction of indep and dep var\n",
    "X=data.iloc[:, 1:2].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "# model creation --SLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR_model=LinearRegression() # model creation\n",
    "LR_model.fit(X_train, Y_train) # model fitting --training dataset\n",
    "# prediction ----Test dataset\n",
    "Y_pred=LR_model.predict(X_test)\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f6302fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 26.31545504558741\n",
      "MSE is---> 22846732.236394573\n",
      "MAE is---> 2350.310066459287\n",
      "RMSE is---> 4779.825544556472\n"
     ]
    }
   ],
   "source": [
    "# Extraction of indep and dep var\n",
    "X=data.iloc[:, 2:3].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "# model creation --SLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR_model=LinearRegression() # model creation\n",
    "LR_model.fit(X_train, Y_train) # model fitting --training dataset\n",
    "# prediction ----Test dataset\n",
    "Y_pred=LR_model.predict(X_test)\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3ae08c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 24.045372276458632\n",
      "MSE is---> 23550597.249238525\n",
      "MAE is---> 2411.326008940802\n",
      "RMSE is---> 4852.895759156437\n"
     ]
    }
   ],
   "source": [
    "# Extraction of indep and dep var\n",
    "X=data.iloc[:, 3:4].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "# model creation --SLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR_model=LinearRegression() # model creation\n",
    "LR_model.fit(X_train, Y_train) # model fitting --training dataset\n",
    "# prediction ----Test dataset\n",
    "Y_pred=LR_model.predict(X_test)\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9bf012d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 26.160053916245886\n",
      "MSE is---> 22894916.12615729\n",
      "MAE is---> 2361.7212180324564\n",
      "RMSE is---> 4784.863229618721\n"
     ]
    }
   ],
   "source": [
    "# Extraction of indep and dep var\n",
    "X=data.iloc[:, 4:5].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "# model creation --SLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR_model=LinearRegression() # model creation\n",
    "LR_model.fit(X_train, Y_train) # model fitting --training dataset\n",
    "# prediction ----Test dataset\n",
    "Y_pred=LR_model.predict(X_test)\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0bd2b58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 25.811841116544876\n",
      "MSE is---> 23002883.46993306\n",
      "MAE is---> 2374.247000304831\n",
      "RMSE is---> 4796.132136412951\n"
     ]
    }
   ],
   "source": [
    "# Extraction of indep and dep var\n",
    "X=data.iloc[:, 5:6].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "# model creation --SLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR_model=LinearRegression() # model creation\n",
    "LR_model.fit(X_train, Y_train) # model fitting --training dataset\n",
    "# prediction ----Test dataset\n",
    "Y_pred=LR_model.predict(X_test)\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "911ab870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 89.15426517446578\n",
      "MSE is---> 3362843.5870673195\n",
      "MAE is---> 1118.803249313238\n",
      "RMSE is---> 1833.8057659052442\n"
     ]
    }
   ],
   "source": [
    "# Extraction of indep and dep var\n",
    "X=data.iloc[:, 6:7].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# splitting the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "# model creation --SLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "LR_model=LinearRegression() # model creation\n",
    "LR_model.fit(X_train, Y_train) # model fitting --training dataset\n",
    "# prediction ----Test dataset\n",
    "Y_pred=LR_model.predict(X_test)\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7938741a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 26.616488275112914\n",
      "MSE is---> 22753393.455603004\n",
      "MAE is---> 2345.009838498867\n",
      "RMSE is---> 4770.051724625531\n"
     ]
    }
   ],
   "source": [
    "#application of multiple linear regressions to find total traded quantity\n",
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "cc27cd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 24.46321018629064\n",
      "MSE is---> 23421041.847219653\n",
      "MAE is---> 2392.6804761199246\n",
      "RMSE is---> 4839.529093539954\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,3]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "140f7af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 26.208822494942808\n",
      "MSE is---> 22879794.872986387\n",
      "MAE is---> 2361.235499852742\n",
      "RMSE is---> 4783.282855214229\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,4]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "316bf47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 25.86168908560661\n",
      "MSE is---> 22987427.539488133\n",
      "MAE is---> 2374.197244361036\n",
      "RMSE is---> 4794.5205745192225\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,5]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4e661b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 96.34461108441985\n",
      "MSE is---> 1133394.9585467738\n",
      "MAE is---> 736.1511957166249\n",
      "RMSE is---> 1064.6102378555138\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,6]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "28d1eeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 28.93405828070106\n",
      "MSE is---> 22034804.48434003\n",
      "MAE is---> 2293.1479643666476\n",
      "RMSE is---> 4694.124464086996\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [2,3]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "79f84011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 26.312652454566788\n",
      "MSE is---> 22847601.211654663\n",
      "MAE is---> 2350.7659715622035\n",
      "RMSE is---> 4779.916444003458\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [2,4]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "86e198c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 26.27492852105251\n",
      "MSE is---> 22859297.946817204\n",
      "MAE is---> 2351.7082499687835\n",
      "RMSE is---> 4781.139816698232\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [2,5]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "2544fb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 96.45163729358096\n",
      "MSE is---> 1100210.2636491796\n",
      "MAE is---> 729.6384693837009\n",
      "RMSE is---> 1048.9090826421418\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [2,6]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "35877bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 30.792687466403823\n",
      "MSE is---> 21458515.340412077\n",
      "MAE is---> 2307.6127254276184\n",
      "RMSE is---> 4632.333681894265\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [3,4]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5b38eb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 33.2342144752183\n",
      "MSE is---> 20701492.088754345\n",
      "MAE is---> 2259.2456917773306\n",
      "RMSE is---> 4549.8892391743275\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [3,5]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "4c20cd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 96.38135875224417\n",
      "MSE is---> 1122000.9256785007\n",
      "MAE is---> 730.2009708640736\n",
      "RMSE is---> 1059.2454511011604\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [3,6]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "25bbe9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 26.059709202079915\n",
      "MSE is---> 22926029.14744697\n",
      "MAE is---> 2366.339250836012\n",
      "RMSE is---> 4788.113318150164\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [4,5]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "89361e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 96.44368420861318\n",
      "MSE is---> 1102676.2082081721\n",
      "MAE is---> 725.4897380219065\n",
      "RMSE is---> 1050.0839053181285\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [4,6]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b72d06e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 96.45281378573219\n",
      "MSE is---> 1099845.4788605382\n",
      "MAE is---> 725.3022795791046\n",
      "RMSE is---> 1048.7351805201056\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [5,6]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "845103ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 28.87971241009214\n",
      "MSE is---> 22051655.040378936\n",
      "MAE is---> 2291.914189633077\n",
      "RMSE is---> 4695.918977194872\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2,3]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4c0e6646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 26.695121804867227\n",
      "MSE is---> 22729012.234273475\n",
      "MAE is---> 2344.9149232204118\n",
      "RMSE is---> 4767.495383770547\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2,4]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cfa6cbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 26.60146387265787\n",
      "MSE is---> 22758051.942672644\n",
      "MAE is---> 2347.6513185449953\n",
      "RMSE is---> 4770.54000535292\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2,5]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "362328ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Score----> 96.43834289891915\n",
      "MSE is---> 1104332.342102284\n",
      "MAE is---> 730.3604622734098\n",
      "RMSE is---> 1050.872181619765\n"
     ]
    }
   ],
   "source": [
    "# predicting tottal traded quantity with opening and low and high price\n",
    "# Extraction of Indep and Dep\n",
    "X= data.iloc[: , [1,2,6]].values\n",
    "Y=data.iloc[:, 7:8].values\n",
    "# Splitting the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Feature scalling ---Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Model creation ---MLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "MLR=LinearRegression()\n",
    "MLR.fit(X_train, Y_train) # fit the dataset\n",
    "\n",
    "# Predection ---perfromed on test dataset\n",
    "Y_pred=MLR.predict(X_test)\n",
    "\n",
    "# Evaluate the perfromance \n",
    "# metrics:-r2_score, mse, rmse, mae\n",
    "import math\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('R2_Score---->', r2_score(Y_test, Y_pred)*100)\n",
    "print('MSE is--->',mean_squared_error(Y_test, Y_pred))\n",
    "print('MAE is--->',mean_absolute_error(Y_test, Y_pred))\n",
    "print('RMSE is--->',math.sqrt(mean_squared_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7ece3d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7bf384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ed1e37f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date    Open    High     Low    Last   Close  Total Trade Quantity  \\\n",
      "0  08/10/2018  208.00  222.25  206.85  216.00  215.15             4642146.0   \n",
      "1  05/10/2018  217.00  218.60  205.90  210.25  209.20             3519515.0   \n",
      "2  04/10/2018  223.50  227.80  216.15  217.25  218.20             1728786.0   \n",
      "3  03/10/2018  230.00  237.50  225.75  226.45  227.60             1708590.0   \n",
      "4  01/10/2018  234.55  234.60  221.05  230.30  230.90             1534749.0   \n",
      "\n",
      "      Turnover stock_price_change_in _percentage  trend  \n",
      "0  10062.83000                            3.4375      2  \n",
      "1   7407.06000                      -3.594470046      1  \n",
      "2   3815.79000                      -2.371364653      1  \n",
      "3   3960.27000                      -1.043478261      1  \n",
      "4   4839.84392                      -1.556171392      1  \n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X=data.iloc[:, 2:4].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'Country'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "84c3a419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X), type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e357b53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  0 134   0]\n",
      " [  0 112   0]]\n",
      "54.25101214574899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.54      1.00      0.70       134\n",
      "           2       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.54       247\n",
      "   macro avg       0.18      0.33      0.23       247\n",
      "weighted avg       0.29      0.54      0.38       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X=data.iloc[:, 2:4].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "2061c6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  0 134   0]\n",
      " [  0 112   0]]\n",
      "54.25101214574899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.54      1.00      0.70       134\n",
      "           2       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.54       247\n",
      "   macro avg       0.18      0.33      0.23       247\n",
      "weighted avg       0.29      0.54      0.38       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X=data.iloc[:, 1:2].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "323d77ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  0 134   0]\n",
      " [  0 112   0]]\n",
      "54.25101214574899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.54      1.00      0.70       134\n",
      "           2       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.54       247\n",
      "   macro avg       0.18      0.33      0.23       247\n",
      "weighted avg       0.29      0.54      0.38       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X=data.iloc[:, 2:3].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "2803c98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  0 134   0]\n",
      " [  0 112   0]]\n",
      "54.25101214574899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.54      1.00      0.70       134\n",
      "           2       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.54       247\n",
      "   macro avg       0.18      0.33      0.23       247\n",
      "weighted avg       0.29      0.54      0.38       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X=data.iloc[:, 3:4].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "905862d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  0 134   0]\n",
      " [  0 112   0]]\n",
      "54.25101214574899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.54      1.00      0.70       134\n",
      "           2       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.54       247\n",
      "   macro avg       0.18      0.33      0.23       247\n",
      "weighted avg       0.29      0.54      0.38       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X=data.iloc[:, 4:5].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "3a2226a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  0 134   0]\n",
      " [  0 112   0]]\n",
      "54.25101214574899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.54      1.00      0.70       134\n",
      "           2       0.00      0.00      0.00       112\n",
      "\n",
      "    accuracy                           0.54       247\n",
      "   macro avg       0.18      0.33      0.23       247\n",
      "weighted avg       0.29      0.54      0.38       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X=data.iloc[:, 5:6].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "5ed44f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  0 123  11]\n",
      " [  0 100  12]]\n",
      "54.655870445344135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.55      0.92      0.69       134\n",
      "           2       0.52      0.11      0.18       112\n",
      "\n",
      "    accuracy                           0.55       247\n",
      "   macro avg       0.36      0.34      0.29       247\n",
      "weighted avg       0.53      0.55      0.45       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X=data.iloc[:, 6:7].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b22e324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  0 128   6]\n",
      " [  0 101  11]]\n",
      "56.2753036437247\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.56      0.96      0.70       134\n",
      "           2       0.65      0.10      0.17       112\n",
      "\n",
      "    accuracy                           0.56       247\n",
      "   macro avg       0.40      0.35      0.29       247\n",
      "weighted avg       0.60      0.56      0.46       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X=data.iloc[:, 7:8].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "9d9cdda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   1]\n",
      " [  0 134   0]\n",
      " [  0 106   6]]\n",
      "56.68016194331984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.56      1.00      0.72       134\n",
      "           2       0.86      0.05      0.10       112\n",
      "\n",
      "    accuracy                           0.57       247\n",
      "   macro avg       0.47      0.35      0.27       247\n",
      "weighted avg       0.69      0.57      0.43       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,2]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "90de65ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   1]\n",
      " [  0 134   0]\n",
      " [  0 101  11]]\n",
      "58.70445344129555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.57      1.00      0.73       134\n",
      "           2       0.92      0.10      0.18       112\n",
      "\n",
      "    accuracy                           0.59       247\n",
      "   macro avg       0.50      0.37      0.30       247\n",
      "weighted avg       0.73      0.59      0.47       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,3]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "6ab072ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   1]\n",
      " [  0 134   0]\n",
      " [  0  54  58]]\n",
      "77.7327935222672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.71      1.00      0.83       134\n",
      "           2       0.98      0.52      0.68       112\n",
      "\n",
      "    accuracy                           0.78       247\n",
      "   macro avg       0.57      0.51      0.50       247\n",
      "weighted avg       0.83      0.78      0.76       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,4]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "b4c6a569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   1]\n",
      " [  0 134   0]\n",
      " [  0  48  64]]\n",
      "80.16194331983806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.74      1.00      0.85       134\n",
      "           2       0.98      0.57      0.72       112\n",
      "\n",
      "    accuracy                           0.80       247\n",
      "   macro avg       0.57      0.52      0.52       247\n",
      "weighted avg       0.85      0.80      0.79       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,5]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "79877b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  0 123  11]\n",
      " [  0  98  14]]\n",
      "55.465587044534416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.55      0.92      0.69       134\n",
      "           2       0.56      0.12      0.20       112\n",
      "\n",
      "    accuracy                           0.55       247\n",
      "   macro avg       0.37      0.35      0.30       247\n",
      "weighted avg       0.55      0.55      0.47       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,6]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "4b99f585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  0 125   9]\n",
      " [  0 100  12]]\n",
      "55.465587044534416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.55      0.93      0.69       134\n",
      "           2       0.57      0.11      0.18       112\n",
      "\n",
      "    accuracy                           0.55       247\n",
      "   macro avg       0.37      0.35      0.29       247\n",
      "weighted avg       0.56      0.55      0.46       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,7]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5d024459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   0   0]\n",
      " [  0 134   0]\n",
      " [  0  94  18]]\n",
      "61.943319838056674\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       0.59      1.00      0.74       134\n",
      "           2       1.00      0.16      0.28       112\n",
      "\n",
      "    accuracy                           0.62       247\n",
      "   macro avg       0.86      0.72      0.67       247\n",
      "weighted avg       0.78      0.62      0.53       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,2,3]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c8b3b175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   1]\n",
      " [  0 134   0]\n",
      " [  0 106   6]]\n",
      "56.68016194331984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.56      1.00      0.72       134\n",
      "           2       0.86      0.05      0.10       112\n",
      "\n",
      "    accuracy                           0.57       247\n",
      "   macro avg       0.47      0.35      0.27       247\n",
      "weighted avg       0.69      0.57      0.43       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,2.4]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "eda72350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   1]\n",
      " [  0 134   0]\n",
      " [  0 106   6]]\n",
      "56.68016194331984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.56      1.00      0.72       134\n",
      "           2       0.86      0.05      0.10       112\n",
      "\n",
      "    accuracy                           0.57       247\n",
      "   macro avg       0.47      0.35      0.27       247\n",
      "weighted avg       0.69      0.57      0.43       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,2.5]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "532df023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   0   0]\n",
      " [  0 132   2]\n",
      " [  0  41  71]]\n",
      "82.5910931174089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       0.76      0.99      0.86       134\n",
      "           2       0.97      0.63      0.77       112\n",
      "\n",
      "    accuracy                           0.83       247\n",
      "   macro avg       0.91      0.87      0.88       247\n",
      "weighted avg       0.86      0.83      0.82       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,2,3,4,5,6]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e663d91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   1]\n",
      " [  0 134   0]\n",
      " [  0 106   6]]\n",
      "56.68016194331984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.56      1.00      0.72       134\n",
      "           2       0.86      0.05      0.10       112\n",
      "\n",
      "    accuracy                           0.57       247\n",
      "   macro avg       0.47      0.35      0.27       247\n",
      "weighted avg       0.69      0.57      0.43       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,2]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d65b5042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   0   0]\n",
      " [  0 134   0]\n",
      " [  0  52  60]]\n",
      "78.94736842105263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       0.72      1.00      0.84       134\n",
      "           2       1.00      0.54      0.70       112\n",
      "\n",
      "    accuracy                           0.79       247\n",
      "   macro avg       0.91      0.85      0.85       247\n",
      "weighted avg       0.85      0.79      0.77       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,2,3,4]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "98de5106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   1]\n",
      " [  0 134   0]\n",
      " [  0  46  66]]\n",
      "80.97165991902834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.74      1.00      0.85       134\n",
      "           2       0.99      0.59      0.74       112\n",
      "\n",
      "    accuracy                           0.81       247\n",
      "   macro avg       0.58      0.53      0.53       247\n",
      "weighted avg       0.85      0.81      0.80       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [1,2,5]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f81f70ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  0 121  13]\n",
      " [  0 100  12]]\n",
      "53.84615384615385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.55      0.90      0.68       134\n",
      "           2       0.48      0.11      0.18       112\n",
      "\n",
      "    accuracy                           0.54       247\n",
      "   macro avg       0.34      0.34      0.28       247\n",
      "weighted avg       0.51      0.54      0.45       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [4,5,6]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ab88aa49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   1   0]\n",
      " [  0 121  13]\n",
      " [  0  98  14]]\n",
      "54.655870445344135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.55      0.90      0.68       134\n",
      "           2       0.52      0.12      0.20       112\n",
      "\n",
      "    accuracy                           0.55       247\n",
      "   macro avg       0.36      0.34      0.30       247\n",
      "weighted avg       0.53      0.55      0.46       247\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\shaurya khanna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#predicting trend via logistic regression\n",
    "# Extraction of Indep and Dep var\n",
    "X= data.iloc[: , [6,7]].values\n",
    "Y=data.iloc[:, 9:].values\n",
    "# Import label encoder \n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'trend'. \n",
    "data['trend']= label_encoder.fit_transform(data['trend']) \n",
    "# split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# feature scalling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "# model creation ----Logistic Regression ---Classifcation ---Target column contain Disc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LRC=LogisticRegression()\n",
    "LRC.fit(X_train, Y_train)\n",
    "\n",
    "# prediction ---Test dataset---X_test\n",
    "Y_pred=LRC.predict(X_test)\n",
    "# To evaluate the perfromance of model\n",
    "# Creating the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "# Inbuilt method accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_test, Y_pred)*100)\n",
    "\n",
    "# Complete perfromance report \n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d133c295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [2],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda47d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
